<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[J.U.C源码阅读笔记（五）线程池]]></title>
    <url>%2F2020%2F04%2F23%2FThreadPool%2F</url>
    <content type="text"><![CDATA[线程池是存放线程的容器，内部维护了若干个线程。通过利用线程池可以避免频繁创建线程，销毁线程带来的系统内耗，提高吞吐量。在Java中用Thread对线程做了抽象，线程池的实现类是ThreadPoolExecutor。但是线程之间的切换需要系统调用进内核，一旦线程池中线程的数量比较多，线程切换带来的内耗会制约系统吞吐量。协程(在Windows上称为纤程)本质上是用户态的线程，协程的调度不需要进内核，在用户态即可完成，所以相对线程，协程更加轻量。在Java中Quasar、 Loom库中实现了协程。 Java线程池类结构下图是Java中关于线程池的类的组织架构。顶层接口是Executor，里面只有一个execute(Runnable command)方法,ExecutorService扩展了顶层接口，添加了关闭线程池等方法，AbstractExecutorService 实现了ExecutorService中的部分方法。而真正要用到的类是ThreadPoolExecutor。 ThreadPoolExecutor部分源码解读属性ThreadPoolExecutor主要属性包括线程池的状态以及线程池中工作线程的数量。ThreadPoolExecutor构造函数中包含了如下变量： corePoolSize 核心线程数量 maximumPoolSize 线程池所允许的最大线程数量 keepAliveTime 线程存活时间（一般指corePoolSize和maximumPoolSize这些线程的存活时间，当调用allowCoreThreadTimeout()后，核心线程也可以超时退出） TimeUnit 超时单位（毫秒、秒等） BlockingQueue 阻塞队列用于存放任务 ThreadFactory 创建线程的工厂，可以用来根据业务用来设置线程的名字 线程池状态属性123456789101112131415161718192021222324252627282930313233343536// 工具数字，29。后面会用它进行位运算，创建线程池的状态private static final int COUNT_BITS = Integer.SIZE - 3;// 工具数字，后面利用它计算线程池的状态和线程池中工作线程数量。// 线程池中最大可以创建的线程数量（2^29 - 1）：00011111 11111111 11111111 11111111private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;/* 用int的高 3 位表示[线程池]的状态，低 29 位存放线程池中工作线程数量 */// 正在运行：允许接收任务，处理任务队列中的任务// 11100000 00000000 000000000 00000000private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 关闭状态：不再接收新的任务，但会处理任务队列中的任务// 00000000 00000000 000000000 00000000private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;// 停止状态：不再接收新的任务，也不会处理任务队列中的任务，并且会中断正在执行任务的线程// 00100000 00000000 000000000 00000000private static final int STOP = 1 &lt;&lt; COUNT_BITS;// 正在整理中：所有的任务都已经终止，工作线程数量为 0，然后就会执行钩子函数 terminated()，转到终止状态，可以重写钩子函数。// 01000000 00000000 000000000 00000000private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;// 终止状态：线程池彻底终止，当处于TIDYING状态线程池执行完钩子函数terminated()就会转换成这个状态// 01100000 00000000 000000000 00000000private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// ctl高 3 位存储线程池的状态，低 29 位存储工作线程数量，ctl初始值为 -1。内部大量用到了ctl变量。private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;// 将整数 c 的低 29 位修改为 0，就得到了线程池的状态（~CAPACITY = 11100000 00000000 00000000 00000000）private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 将整数 c 的高 3 为修改为 0，就得到了线程池中的线程数（CAPACITY = 00011111 11111111 11111111 11111111）private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; 线程池状态转换因为在创建工作线程以及任务执行过程中需要不断地的判断线程池状态，所以有必要了解:) RUNNING -&gt; SHUTDOWN：On invocation of shutdown(), perhaps implicitly in finalize() (RUNNING or SHUTDOWN) -&gt; STOP：On invocation of shutdownNow() SHUTDOWN -&gt; TIDYING：When both queue and pool are empty STOP -&gt; TIDYING：When pool is empty 因为 STOP 状态不会在去处理队列中的任务，所以只需要考虑线程池中的线程数量 TIDYING -&gt; TERMINATED：When the terminated() hook method has completed 执行任务源码public void execute(Runnable command)在将来某个时间执行给定的任务（将来的意思是任务可能会放到任务队列中），可能创建线程执行也可能利用现有的线程执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public void execute(Runnable command) &#123; // 预处理 if (command == null) throw new NullPointerException(); /* * 线程池处理任务分为 3 个步骤： * * 步骤 1. * 如果当前工作线程数量少于核心线程数，会尝试通过 addWorker(Runnable fisrtTask, boolean core) 创建线程执行 "给定的任务" * 此时 firstTask 为给定的任务，core 为 true 代表工作线程数量边界为 "核心线程数量" * 但是由于意外情况，addWorker 可能会失败: 比如执行 addWorker 时线程池状态变为 Shutdown、Stop 或者由于系统资源不* 够（当前用户进程 limit 受限 ulimit -u），导致 new Thread() 直接失败(抛 can not create native thread 异常) * 所以如果 addworker 方法返回 false 说明存在意外情况导致创建失败，直接返回。 * * 步骤 2. * 当步骤 1 不能处理时，说明当前线程数量 &gt;= 核心线程数量 * 如果处于 RUNNING 状态，并且任务成功入队后，会二次判断线程池状态 * 当处于未运行状态时会将刚才入队的任务出队，同时执行拒绝策略 * 当工作线程数量为 0 时(线程超时退出、异常退出)，会尝试创建新的工作线程, 最终就是要保证，如果线程池处于正常状态，就务必要成功执行 addWorker() * * 步骤 3. * 当步骤 2 不能处理时，说明线程池没有运行或者队列已经满了，此时会尝试创建新的工作线程 * 通过将 core 设置为 false，此时工作线程数量的边界为最大线程数量 * 如果创建工作线程失败，代表线程池处于未运行状态或者已经饱和，会尝试执行拒绝策略 */ int c = ctl.get(); // 对应上述步骤 1 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 对应上述步骤 2 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 如果线程池已经关闭，需要移除之前提交到队列中的任务，并执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 防止线程池没有关闭，但是工作线程数量为0(因为线程有存活时间或者出现异常情况) else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 对应步骤 3 else if (!addWorker(command, false)) reject(command);&#125; private boolean addWorker(Runnable firstTask, boolean core)创建工作线程，每个 Worker 内部维护一个Thread，也可以想成每个 Worker 是对 Thread 的抽象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; // 获取线程池状态 int c = ctl.get(); int rs = runStateOf(c); /* * 步骤1. 检查线程池的状态 * 如果处于SHUTDOWN、STOP、TIDYING、TERMINATED状态时，一般就不再创建新的线程了，但是要处理一种特殊情况: * 当线程池状态处于 SHUTDOWN 时，尽管不需要处理新来的任务，但是需要处理完阻塞队列中的任务 * 所以，当线程池状态为 SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; !workQueue.isEmpty()，还会允许添加 Worker 执行队列中的任务 */ if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; /* * 步骤2. 判断当前线程数量和边界值，修改 worker 值 */ for (;;) &#123; int wc = workerCountOf(c); // 比较工作线程数量和边界CAPACITY，CAPACITY根据core的值动态调整 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 尝试将c中保存的工作线程数量加 1， // 如果修改成功，会通过break，跳出外层循环到retry。 // 如果修改失败，说明有并发操作，此时会比较当前线程池的状态和进入这个方法时线程池的状态 // 如果状态不一致，说明线程池状态发生的变化，会通过continue重新进入外层for循环，重新走一遍逻辑，避免在线程池关闭之类的状态下执行后续的操作 // 如果状态一致，会重新在内层for循环中尝试修改ctl if (compareAndIncrementWorkerCount(c)) break retry; // 判断当前线程池的状态和进入这个方法时线程池的状态是否一致 c = ctl.get(); if (runStateOf(c) != rs) continue retry; &#125; &#125; /* * 步骤3. 正式创建工作线程并启动它。 * Thread会被封装到Worker中 */ // 工作线程是否启动 boolean workerStarted = false; // 工作线程是否已经创建 boolean workerAdded = false; Worker w = null; try &#123; // 创建工作线程 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; // 获取到锁以后才尝试创建线程，因为在关闭线程池时也需要获取到这把锁 // 为了防止 [当关闭线程池以后并且也释放了这把锁]，当获取到锁后还会重新检测线程池的状态，拿到锁以后，也就避免此时不会关闭线程池 mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); // 只有线程池正在运行 或者 处于前面说的特殊情况 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将包装的Worker放到集合中 workers.add(w); // 记录线程池中线程数量的峰值，统计用。 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 成功创建worker以后，会将worker中包装的Thread启动 if (workerAdded) &#123; // 启动Woker类里的Thread对象，因为Worker实现了Runnable // 此时新创建的线程就会执行Worker中的run()方法。 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 启动线程出现意外情况，执行相应的处理方法 if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; private void addWorkerFailed(Worker w)处理 [创建工作线程出现的失败情况]，会将之前放到集合中的Worker对象移除，并且将ctl变量中保存的工作线程数量减1 12345678910111213private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); // 添加线程失败，线程池可能处于异常状态，尝试中断线程 tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; public void run()创建的线程会从run方法开始执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 作为runWorker(Worker w)的代理方法，在Worker中实现public void run() &#123; runWorker(this);&#125;// 在ThreadPoolExecutor中实现// 整体逻辑就是不断地的从任务队列中取任务执行final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; // 因为线程会被复用，将firstTask置为空避免重复执行 w.firstTask = null; // 允许被中断（当调用shutdownnow时，需要获取锁 w ，然后中断 w 封装的线程） w.unlock(); // 用于判断线程是否是在执行用户任务过程中出现的异常退出的 boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // 如果线程池处于未运行状态，需要确保当前线程被中断 // 否则，需要确保当前线程不能被中断 // 重复调用 runStateAtLeast(ctl.get(), STOP) 是为了避免边界条件： // 第一次runStateAtLeast(ctl.get(), STOP)返回false，当执行 || 右侧的Thread.interrupted()时，线程池停止了，但还没中断当前线程 // 此时需要线程自我中断 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); // beforeExecute(wt, task); 和 afterExecute(task, thrown); 都是钩子方法 try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; // 正式执行用户提交的任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; // 记录完成的任务数量 w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 当线程在执行任务中抛了异常，会转到这里 // 此时当前线程结束，如果线程池没有关闭，会重新创建一个线程代替当前线程 processWorkerExit(w, completedAbruptly); &#125;&#125; private Runnable getTask()线程会不断地尝试获取任务，当取任务超时后，会在符合预先条件的情况下结束当前线程：此时getTask()会返回null，线程结束在runWorker(Worker w)中的while循环。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private Runnable getTask() &#123; // 标识线程是否超时 boolean timedOut = false; // Did the last poll() time out? // 直到超时、线程池关闭或者拿到任务才会退出 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 判断线程池是否关闭，如果关闭了，符合特殊情况：（SHUTDOWN并且工作队列为空）或 （线程池状态是STOP及以上） if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; // 减少线程数 decrementWorkerCount(); // 返回null以后，这个线程会正常结束 return null; &#125; int wc = workerCountOf(c); // 判断是否允许[所有]线程超时退出 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 如果用户调用了setMaximumPoolSize()会导致wc &gt; maximumPoolSize // 如果 （允许所有线程超时 或者 当前线程数量已经超过corePoolSize） 并且当前线程已经超时了 // 此时需要结束当前线程（通过返回null） if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 阻塞获取任务，如果在指定时间段内没有获取到，会返回null // timed表示是否应该超时获取，注意此处也是 keepAliveTime 起作用的地方 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 未超时的情况下获取到了任务，直接返回 if (r != null) return r; // 超时了，下次进入循环中时会返回null timedOut = true; &#125; catch (InterruptedException retry) &#123; // 被中断了会重试：可能调用setMaximumPoolSize方法，setMaximumPoolSize执行会中断线程 timedOut = false; &#125; &#125;&#125; public interface RejectedExecutionHandlerThreadPoolExecutor基于RejectedExecutionHandler提供了四种拒绝策略，自己也可以基于RejectedExecutionHandler定制拒绝策略。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 让提交任务的线程去执行public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125;// 直接拒绝，并且抛出异常public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException("Task " + r.toString() + " rejected from " + e.toString()); &#125;&#125;// 直接丢弃，不抛出异常public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125;// 丢弃任务队列中最老的任务，也就是队列中队头，然后重新尝试将当前任务入队。public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; 关闭线程池12345678910111213141516public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 检查调用 shutdown 的线程是否权限关闭线程池（针对里面的每个worker） checkShutdownAccess(); // 死循环修改线程池状态为 SHUTDOWN advanceRunState(SHUTDOWN); // 中断线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125; ScheduledThreadPoolExecutor 源码解读ScheduledThreadPoolExecutor 为定时线程池， 可以周期性的执行任务，文档： Q&amp;A线程池工作流程？ 线程池的种类？线程池的种类也就是线程池工具类 Executors中提供的线程池，实际上也就是通过调整ThreadPoolExecutor以及ScheduledThreadPoolExecutor构造函数中的参数。不过阿里巴巴手册中不建议用这个工具类，所以就简单看一下在ThreadPoolExectuor的构造函数中如何“搭配”变量。 固定数量的线程池：核心线程和最大线程数量一样。 1return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); 单线程线程池：核心线程和最大线程数量都为1 1return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); 缓存线程池：最大线程数量为Integer.MAX_VALUE也可以认为是无界的，尽管会提高性能，但一般不会用这个，因为会创建大量的线程执行。 1return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); 定时线程池 1return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); 线程在执行任务中出现异常会怎么办？参照runWorker()中，当线程在执行任务时抛出了异常，会触发processWorkerExit(w, completedAbruptly);此时当前线程结束，如果线程池没有关闭，会重新创建一个线程代替当前线程 执行拒绝策略的时刻？ 达到边界条件：任务队列满了，工作线程数量达到最大线程数量。 非边界条件：当工作线程数量达到了核心线程数量，此时如果入队成功 =&gt; 如果线程池已经关了，会尝试移除刚才入队的任务。如果移除成功 =&gt; 会执行拒绝策略 拒绝策略使用注意事项？注意在使用 Future 同时使用 Discard 策略时，注意设置超时时间，因为当执行了这个策略后，后续又执行了 Future.get()，此时会卡住当前线程，所以需要加上超时时间或者使用其他拒绝策略 参考 深度解读 java 线程池设计思想及源码实现 OpenJDK8 ThreadPoolExecutor源码]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记]]></title>
    <url>%2F2019%2F06%2F03%2FDesign-Pattern%2F</url>
    <content type="text"><![CDATA[In software engineering, a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design. It is not a finished design that can be transformed directly into source or machine code. It is a description or template for how to solve a problem that can be used in many different situations. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system. — Wikipedia 总结一下，设计模式就是针对某类问题提出的通用的、可复用的最佳实践。设计模式一共分为三大类，分别是创建型模式、结构型模式、行为型模式。 参考 维基百科-设计模式 图说设计模式 Head First 设计模式 创建型模式创建型模式的作用就是用来创建对象，在不同的上下文中以合适的方式创建对象。创建型模式又分为对象创建型模式和类创建型模式。对象创建型模式把对象创建的一部分推迟到另一个对象中，而类创建型模式将它对象的创建推迟到子类中。 简单工厂模式定义一个工厂类，根据客户端传入的不同参数，返回不同的对象，返回的对象同属一个父类。 应用场景工厂类负责创建的对象较少，客户端不需要知道指定类的名字，只需要知道表示该类的一个参数，并提供一个方法，将该参数传入该方法就可以很方便地获取该类的实例。 角色 产品工厂：负责创建所有产品的工厂，负责实现创建所有产品的逻辑 抽象产品：所有具体产品的父类 具体产品：产品工厂具体要创建的产品实例 特性 优点 简单工厂模式可以分担客户端创建对象的责任，客户端只需要使用对象即可，符合类的单一职责原则，有利于解耦合。 缺点 当增加新的产品时，需要修改原有工厂代码，不符合开闭原则。 工厂类负责了所有对象的创建，当要创建的对象过多的话，业务逻辑过于复杂，职责过重。 具体应用JDK中的用于格式化时间的DateFormat 123public final static DateFormat getDateInstance();public final static DateFormat getDateInstance(int style);public final static DateFormat getDateInstance(int style, Locale locale); 工厂方法模式不同类型的对象使用不同的工厂创建，通过定义一个创建对象的接口，但让实现这个接口的类来决定负责创建哪个类的实例 应用场景如果在未来可能会增加新的产品类型，此时用简单工厂模式的话，需要修改原有工厂模式中的代码(添加额外的判断逻辑)，违反了开闭原则，扩展性不好。使用工厂方法模式的话，只需要添加一个针对此产品类型的工厂即可，符合开闭原则。 角色 抽象工厂：定义了创建对象的方法，所有创建对象的具体工厂需要实现这个接口，重写创建对象的方法。 具体工厂：用来创建具体类型产品的实例 抽象产品：所有具体类型产品的父类 具体产品：具体要创建的产品类型，不同类型的产品使用不同的工厂创建 特性 优点 避免了简单工厂模式中的由单一工厂创建所有对象的职责。符合对扩展开放，对修改关闭的原则。 缺点 当增加新产品类型时需要定义新的产品类和与之对应的具体工厂类，导致类的数量成对增加，增加了系统的复杂度。 具体应用JDK中的Iterator和Collection。Iterator相当于一个抽象产品，具体的产品有Itr、KeyIterator。Collection相当于一个抽象工厂，具体的工厂有ArrayList负责创建具体的Itr,HashSet负责创建具体的KeyIterator。 123456789List iteratorFactory = new ArrayList(); // 具体工厂Iterator iterator = iteratorFactory.iterator();public Iterator&lt;E&gt; iterator() &#123; // 抽象产品 return new Itr();&#125;private class Itr implements Iterator&lt;E&gt;; // 具体产品 12345678910111213141516171819202122232425Set iteratorFactory = new HashSet&lt;&gt;(); // 具体工厂Iterator iterator = iteratorFactory.iterator();public Iterator&lt;E&gt; iterator() &#123; // 抽象产品 return map.keySet().iterator();&#125;public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks;&#125;final class KeySet extends AbstractSet&lt;K&gt; &#123; public final Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125;&#125;final class KeyIterator extends HashIterator // 具体的产品 implements Iterator&lt;K&gt; &#123; public final K next() &#123; return nextNode().key; &#125;&#125; 抽象工厂模式提供一个创建一系列相关或独立对象的接口，而无须指定这些对象的具体类。在抽象工厂模式中，每一个具体工厂都提供了多个工厂方法创建不同类型的产品，这些产品构成了一个产品族。 应用场景当需要工厂负责创建多个对象时，而不是单一对象。需要用到抽象工厂模式。抽象工厂模式面向的是产品族，通过将一系列的产品组成一个产品族，交给一个具体工厂去创建。 角色 抽象工厂： 声明了一组创建一族产品的方法，每一个方法负责创建一种具体类型的产品。 具体工厂： 每一个具体工厂负责创建一组产品，这组产品属于一个产品族 抽象产品： 某种具体类型产品的父类 具体产品： 某种具体的产品 特性 优点 减小了工作量，避免了工厂方法模式中，每次添加一个新的产品，都需要添加一个具体的工厂类与之对应。 会保证客户端使用的都是一个产品族中的产品 当增加新的产品族时，不用修改现有的业务逻辑，符合开闭原则。 缺点 当增加新的产品等级(产品类型)，需要修改抽象工厂(添加创建该产品的方法)以及所有的具体工厂，违背了开闭原则。 具体应用JDK中的java.sql中的Connection是抽象工厂，具体的工厂有MysqlCollectionImpl，里面有创建不同产品中的API，负责创建Statement、PreparedStatement、CallableStatement一系列抽象产品，具体产品有StatementImpl、PreparedStatementImpl、 CallableStatementImpl。 123Statement createStatement() throws SQLException;PreparedStatement prepareStatement(String sql) throws SQLException;CallableStatement prepareCall(String sql) throws SQLException; 单例模式确保应用中某一个类只有一个该类的实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象创建型模式。 应用场景系统只需要一个实例对象，比如只需要一个工具类对象负责读取配置信息。 角色 单例类：负责创建该类的实例 特性 优点 保证整个应用中只有一个该类的实例，避免了频繁的创建对象和销毁对象，节约系统资源。 缺点 将创建对象的职责和执行业务逻辑的职责都交给单例对象，违背了单一职责原则。 单例模式没有做抽象，所以扩展性比较差。 具体使用 JDK中的 RunTime符合单例模式 1234567RunTime runTime = Runtime.getRuntime();private static Runtime currentRuntime = new Runtime();public static Runtime getRuntime() &#123; return currentRuntime;&#125; 饿汉式 123456789public class Singleton &#123; private static final Singleton INSTANCE = new Singleton(); public static Singleton getInstance() &#123; return INSTANCE; &#125;&#125; 懒汉式 1234567891011121314151617181920/** * 双检测 * * */public class Singleton &#123; private static volatile Singleton instance; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 123456789101112131415161718/** * 静态内部类 * * */public class Singleton &#123; private Singleton()&#123;&#125; // 加载InnerClass的初始化阶段是线程安全的，并且只会加载一次。 private static class InnerClass &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getInstance() &#123; return InnerClass.INSTANCE; &#125;&#125; 1234567/** * 枚举 * * */public enum Singleton &#123; INSTANCE;&#125; 建造者模式通过抽象一个建造者来完成对复杂对象的属性注入，使得代码的可读性更好。 应用场景当构建的对象中含有较多的属性时，如果使用构造函数或者setter方法注入的话，整体的代码会比较臃肿。使用建造者模式可以让代码更加优雅一些。 角色 抽象建造者：为创建一个复杂对象的各个组件(属性)指定API，以及一个返回该复杂对象的API 具体建造者：实现了抽象建造者中定义的API 产品：要被构造的复杂对象 特性 优点 优化了复杂对象的创建等，，，相关的博客说了一堆优点，但是并没有完全理解，不想写了:) 缺点 如果产品内部变化复杂，此时就需要定义多个建造者来完成对象的创建，使得系统更复杂。 具体应用JDK中的DocumentBuilder 123public abstract void setEntityResolver(EntityResolver er);public abstract void setErrorHandler(ErrorHandler eh);public abstract Document newDocument(); 原型模式克隆一个已有的对象。 应用场景当需要某个对象作为模板时，只需要在基于这个对象克隆出的对象的基础上，做少量修改就可以得到想要的对象。比如现实中的周报，可以提供一个模板，每个人在这个模板的基础上做少量修改就可以。 具体应用JDK中的clone()可以实现原型模式，不过主要注意的是默认是浅拷贝，如果要克隆的对象含有非原始类型的属性需要重写clone()，实现深拷贝。 另一个就是clone()默认是由protected修饰，只有子类和当前包的类可以访问，如果要让其它类访问的话，需要将protected修改为public。最后就是被克隆的对象要实现Cloneable接口:) 结构型模式通过将类组织成不同的结构，达到解耦合或者是做类增强功能。 代理模式创建目标对象的一个代理对象，来代替目标对象接收客户端请求，代理对象内部维护了目标对象的引用，最终调用目标对象完成客户端的请求，在请求前后可以加上额外的业务逻辑来做对方法进行 “包装” 做增强功能。(TODO：个人理解) 应用场景对于一些非业务逻辑比如记录日志，开启事务，如果和业务代码写在一块，使得整体的耦合性较高，此时可以通过创建代理对象，在执行目标对象方法之前之后加上记录日志的功能来做类增强。 角色 代理类：负责接口客户端请求，要“表现”的和目标类一样，所以要继承自目标类，不过内部持有目标类的引用 目标类：真正执行客户端的请求 特性 优点 将业务代码和非业务代码分离，实现松耦合 缺点 增加了对代理对象的访问，请求会先到达代理对象，然后再到达目标对象，效率会有影响。 具体应用 Spring AOP中用到的是动态代理，通过@Aspect定义一个切面，然后通过@PointCut确定一个切点，在切点前后执行额外的业务逻辑@Advice，执行的时机可以是@Before、@After、@Around Windows里面的快捷方式就是代理对象 装饰者模式通过创建装饰器来装饰对象，对已有对象的功能进行扩展，增强。每一个装饰器内部都维护了抽象对象的引用，可以调用抽象对象的方法，并且可以添加额外的增强方法。 应用场景当不适合用继承的方式对系统进行扩展时，比如系统中存在大量独立的扩展类，如果扩展类之间组合会生成大量的类，此时可以使用装饰者模式 角色 抽象组件：是具体组件和抽象装饰器的父类，抽象装饰器内部维护了抽象组件的引用，使得可以装饰所有的具体组件 具体组件：要被装饰的具体组件，继承自抽象组件 抽象装饰器：内部维护了抽象组件的引用，所以可以调用抽象组件的方法 具体装饰器：继承自抽象装饰器，并且内部有新的方法，来对具体组件做增强功能 特性 优点 当扩展一个对象的功能时，装饰者模式采用类组合来代替继承，不会导致类的数量大幅度增加。 缺点 当对类装饰以后，无法面向接口(抽象)编程，否则无法使用装饰的功能，因为装饰的功能都在具体的装饰器里面。 具体应用JDK中的IO框架，抽象组件是InputStream，具体组件有FileInputStream,抽象装饰器是FilterInputStram，具体的装饰器有BufferedInputStream、DataInputStream 适配器模式通过引入适配器将不兼容的类适配，让这些类的可以一块工作。适配器模式分为对象适配器和类适配器两种，对象适配器指适配者和适配器之间是组合的关系，类适配器指适配者和适配器之间是继承的关系。 应用场景对于已经定义好的接口，但是并没有具体的实现， 不过现有的类可以提供这个接口中定义的功能，但是这个类并没有现成的源代码，比如说只有一个编译好的jar包，此时可以引入一个适配器，适配器实现这个接口，内部持有这个类的引用，通过使用这个类中的功能，间接实现这个接口。 角色 被适配者：已经定义好的接口，但是并没有具体的实现 适配器：将适配者和被适配者适配到一块 适配者：已经有接口中定义的功能，但是和这个接口并不兼容。 特性 优点 实现类的复用，通过适配器复用已有的可以提供服务但是和被适配者不兼容的适配者类 缺点 说的没理解:) TODO：继续看 具体应用JDK中IO框架里的InputStreamReader将InputStream适配成Reader 外观(门面)模式通过创建一个门面角色完成客户端和其它多个子系统复杂的交互流程。 应用场景当系统中类与类之间的交互关系比较复杂，比较多时，比如客户端需要和多个子系统进行交互，可以引入一个外观角色来和这些子系统进行交互。 角色 门面角色：内部持有子系统的引用，将客户端的请求委派给子系统处理。 子系统：执行门面角色传过来的客户端的请求 特性 优点 降低解除了子系统和客户端的耦合性 缺点 当需要修改和子系统交互的执行流程时，需要修改门面角色的代码，违背了开闭原则。 具体应用slf4j相当于一个门面，而Log4J、Log-Back就是子系统。 行为型模式行为型模式重点关注的是类之间的相互作用，将职责划分清楚。 策略者模式策略者模式是指完成一件事情，在不同的上下文里可以采用不同的策略。具体采用哪种策略根据上下文决定 应用场景系统可以选择多种算法来完成某件事情，具体选用那种算法可以根据问题的上下文决定 角色 上下文：问题的上下文 抽象策略：为了给客户端呈现统一的接口 具体策略：对于抽象策略的不同实现 特性 优点 当需要不同的策略时，只需要新创建一个新的策略即可，符合开闭原则。 缺点 可能一些细微的改动，就得创建新的策略，需要创建的类会急剧增加 具体应用JDK中ThreadPoolExecutor中的四种拒绝策略 12345public interface RejectedExecutionHandler; // 抽象策略public static class CallerRunsPolicy implements RejectedExecutionHandler; public static class AbortPolicy implements RejectedExecutionHandler;public static class DiscardPolicy implements RejectedExecutionHandler;public static class DiscardOldestPolicy implements RejectedExecutionHandler; 观察者模式观察者通过订阅它感兴趣的事件，当事件发生时会通知之前订阅它的观察者。 应用场景一个抽象模型有两个方面，其中一个方面依赖于另一个方面，也就是说其它一些对象依赖某一个对象，当这个对象发生改变时，其它这些对象也会跟着变化，也就是一种联动的状态。 角色 抽象观察者：定义了具体要做什么动作的方法 具体观察者：做了具体的实现 抽象观察目标 具体目标：当具体目标发生变化时，会通知订阅它的观察者 特性 优点 观察者模式适合广播通信，观察目标会对所有已经订阅的观察者发送通知 缺点 如果一个观察目标有很多观察者的话，通知所有的观察者会浪费很多的时间 具体应用JDK中对观察者模式做了实现，Observer是观察者 Observerable是观察目标 责任链模式将处理请求的多个处理对象链接成一个链，当请求过来以后，会从链头逐个向链中的节点发送请求。 应用场景一个处理流程需要多个处理人来处理，每个处理人可能有权限处理，可能没权限处理，并且这个处理流程是动态变化的 角色 抽象处理者：定义了处理请求的API 具体处理者：对API做了实现，如果当前处理者没有权限处理，就转交给下一节点处理 特性 优点 可以应付一些动态的处理流程，如果新加处理对象后，只需要客户端重新建链即可。 缺点 处理流程过长会影响效率 具体使用JDK中的类加载器，当AppClassLoader接到类加载请求以后，会交给它的下一节点ExtensionClassLoader，然后交给BootStrapClassLoader。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO模型]]></title>
    <url>%2F2018%2F12%2F03%2FSocket%2F</url>
    <content type="text"><![CDATA[Linux网络IO模型分为同步和异步两种，其中同步IO又包括阻塞IO、非阻塞IO、IO多路复用、信号驱动式IO四种。 预备知识文件 在Unix中,所有东西都是文件,文件可以看作是字节序列。所有的IO设备都可以用文件来描述(文件是对IO设备的抽象): ./dev/sda2 (/usr 磁盘分区) /dev/tty2 (终端) 主要有三种文件类型 普通文件:包含任意数据 文本文件:由ASCII或者Unicode组成 二进制文件:除文本文件外,都是二进制文件(视频,图片,声音) 目录文件:一组文件的索引 Socket文件:用来和其它进程跨网络通信的文件 对文件的操作主要有打开文件、读取文件、关闭文件 打开文件 进程通过系统调用(open()),内核会将文件名转换为一个文件描述符返回给进程(文件描述符是一个整数,进程可以用文件描述符作为索引对应打开的文件). 内核用三个数据结构表示打开的文件,分别是描述符表(descriptor table)、文件列表(file table)、文件列表的描述表(v-node table)。 描述符表 每个进程都有独立的描述符表，它的表项是由文件描述符索引的，每个打开的文件描述符表项指向文件列表中的一个表项。(可以把描述符表当成是一个数组，数组元素类型是文件列表表项，数组下标是文件描述符) 文件列表 文件列表是所有进程已经打开的文件的集合，由内核维护，所有进程共享。每个表项由当前文件的位置、引用计数(即当前志向该表项的描述符表项数)，以及一个指向v-node表的指针。冠以一个文件描述符会减少相应的引用计数。当引用计数为0时内核会删除这个文件列表表项 文件列表描述表 文件列表的元数据表，由内核维护，所有进程共享。 Socket Socket是用来与另一个进程进程进行网络通信的文件类型。进行通信的进程通过系统调用(socket())创建Socket类型文件，通过读写该文件进行通信。通信过程： 客户端进程 socket()创建主动型socket文件(此时的socket还不能使用) connect()发起请求来和服务器建立连接，此时会阻塞线程，直到连接建立(此时socket才可以读写)或者连接失败返回。 服务器进程 socket()创建主动型socket文件(此时的socket还不能使用) bind()绑定到指定的端口 listen()将主动型socket改为监听型socket accept()等待客户端发起请求，进而针对该socket请求创建对应的主动型socket(不同于服务器进程创建的socket文件)，服务器进程通过对主动型的socket进行读写来和客户端进行通信。 IO操作(IO operation) 特指通过系统调用(recvfrom())请求从内核缓冲区拷贝数据到进程内存(copy data from kernel to user), (不包括从设备缓冲区拷贝数据到内核缓冲区) 整个IO请求过程 每个设备都有一个设备控制器(可以类比：每个计算机都有一个CPU，设备控制器是一个微型CPU)，设备控制器也有缓存，操作系统会通过每个设备控制器对应的驱动程序管理设备控制器进行硬件操作。 当线程发起关于IO操作的系统调用后，线程会阻塞，操作系统通过驱动程序控制设备控制器读取数据到设备控制器的缓存中，然后在将设备控制器缓存中的数据读取到操作系统内核缓冲区中，然后通过硬件中断唤醒被阻塞的线程进行后续操作。 Linux IO模型阻塞IO(blocking IO) 执行IO操作时，当内核缓冲区还没有准备好数据时，会阻塞当前线程，直到内核缓冲区中的数据拷贝到进程内存中才会使得线程从阻塞变为就绪状态。 非阻塞IO(nonblocking IO) 在进行IO操作期间，当内核缓冲区中还没有准备好数据，不会阻塞当前线程，会直接返回。线程会一直进行系统调用检测内核中数据是否准备好，如果内核准备好数据以后，并且又收到了线程的IO请求，则会进行数据拷贝，拷贝期间会阻塞当前线程(这不是区分阻塞和非阻塞的因素，因为此时内核缓冲区中已经存在数据)。 在Linux下，通过设置socket为non-blocking，从而实现该模型。 非阻塞IO的特点就是不断地询问内核是否已经准备好数据。 IO多路复用(事件驱动IO、IO multiplexing) 通过单个线程管理多个Socket文件描述符，当至少一个Socket文件描述符可用时就会返回可用文件描述符的数量(select()、poll())或者具体可用的Socket(epoll())。然后线程轮询找到可用的Socket文件描述符,通过IO操作读取数据到用户地址空间(这一步常常配合非阻塞IO,也就是将对Socket的操作改为非阻塞) Linux下，IO多路复用的实现通过select()、poll()、epoll()实现。 当调用select()、poll()、epoll()后线程会阻塞，直到有可用的socket后内核会唤醒线程。然后线程通过轮询(epoll()除外)找到具体可用的socket，进行IO操作。 信号驱动IO(signal driven IO) 应用进程使用sigaction系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达后向应用进程发送SIGIO信号，应用进程收到之后在信号处理程序中执行IO操作(调用recvfrom()将数据从内核复制到应用进程中)。 异步IO(asynchronous IO) 线程发起aio_read()系统调用会立即返回,不会阻塞,而且可以去干其它的事情,内核会等待数据准备好,然后拷贝到进程地址空间,然后以回调的形式通知线程。 几种模型汇总比较 阻塞IO、非阻塞IO、IO多路复用和信号驱动式IO都是同步IO，在IO操作期间都会发生阻塞。主要区别在第一阶段(wait for data),非阻塞IO、IO多路复用、信号驱动式IO在第一阶段不会阻塞。 Q&amp;A阻塞IO、非阻塞IO区分条件？ 内核缓冲区中没有数据时，判断此时进行IO操作是否被阻塞 同步IO与异步IO区别？ A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 为什么IO多路复用需要搭配非阻塞IO？ 比如当内核缓冲区准备好数据时,此时select()会返回,但是后续read()之前:内核检查该数据时,如果出现错误的校验和,就会丢弃该数据,当线程进行IO操作时就会阻塞,从而可能出现安全问题。man select里的一个BUG描述： Under Linux, select() may report a socket file descriptor as “ready for reading”, while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block. select/poll/epoll区别？ select监听的文件描述符数量有限制(1024个),并且返回时只是返回的可用的Socket的数量,并不是具体哪个Socket可用,客户端还得需要轮询找出可用的Socket。 poll解除了文件描述符的数量,但也得轮询找出可用socket。 内核会修改select/poll传入的文件描述符集合，所以每次都需要拷贝文件描述符到内核，所以当socket数量比较多时，会影响效率。 epoll返回时会得到具体可用的Socket描述符,不用去轮询。 select相对于epoll来说是跨平台的，而epoll是针对于Linux的，Windows是使用IOCP实现，OS X使用kqueue实现的。 如果系统存在大量的空闲连接，那每次遍历文件描述符开销会很大，此时可以选用epoll，如果只有很少的连接，可以选用select。 select和epoll工作流程？参考自知乎 select当客户端调用select以后，会挂起当前线程，此时内核会去检测select所监控的socket，当socket可读或者可写了，就会以中断的形式通知select，select就会返回可用的socket的数量，客户端遍历找到可用的socket。 epollepoll维护了一个红黑树用来存放监听的文件描述符,并且注册一个回调函数给内核，当内核发现红黑树上的Socket文件描述符对应的Socket可用时，会将该描述符放到就绪链表中。当内核检测到socket可用时，就会通过注册的回调函数将socket对应的文件描述符放到就绪链表中。epoll就会返回就绪链表。epoll处理文件描述符有两种工作模式，水平触发(level trigger)和边缘触发(edge trigger) 水平触发是指当客户端不处理返回的socket时，就绪链表中不会删除这个socket对应的文件描述符，下次调用epoll_wait()时还会返回这个socket对应的文件描述符 边缘触发是指如果客户端不处理返回的socket时，就绪链表中不会保存这个socket对应的文件描述符，下次调用epoll_wait()就不会返回这个socket对应的文件描述符，直到有新的事件过来。 总结就是，LT模式下，只要某个文件描述上的事件一次没有处理完，会在以后调用epoll_wait()时次次返回这个文件描述符，而ET模式仅在第一次返回，返回以后，会清除就绪链表 Java NIO? Java NIO(New IO)实现了非阻塞IO模型,并且通过Selector选择器实现了IO多路复用模型(Linux2.6之前使用的是select(),2.6之后是epoll(),默认边缘触发) NIO可以实现零拷贝，使得数据直接在内核态进行拷贝，不用再进入用户态。 NIO实现了非阻塞IO模型，并且搭配Selector来实现IO多路复用。 BIO/NIO/AIO区别? BIO是面向流的，而NIO是面向缓冲Buffer的。并且Buffer内部维护了三个指针(position、limit、capacity)可以操作，相对于BIO来说比较灵活。BIO中的流是分方向的（输入流、输出流）。而NIO中的Channel类似于BIO中的流，但是Channel没有方向，可以向Channel中读取数据和写入数据。 AIO是异步IO 参考 I/O Models Linux IO模式及select、poll、epoll详解 Linux IO GitHub笔记 CSAPP第十章、第十一章 为什么IO多路复用要搭配非阻塞IO？ Java NIO NIO BIO]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C源码阅读笔记（四）Lock]]></title>
    <url>%2F2018%2F08%2F15%2FLock%2F</url>
    <content type="text"><![CDATA[Lock接口下的锁是基于AQS实现的显式锁。具体有ReentrantLock、ReentrantReadWriteLock.ReadLock、ReentrantReadWriteLock.WriteLock。相对于synchronized隐式锁，这些锁更灵活。 ReentrantLock1public class ReentrantLock implements Lock, java.io.Serializable 介绍实现了Lock接口，是一个显示可重入锁，并且提供了公平锁和非公平锁的实现。 非公平锁 new ReentrantLock();lock()非公平锁获取锁的过程: 首先会尝试将锁状态state通过CAScompareAndSetState(0, 1)设置为独占模式(修改为1) 如果修改成功，将会调用setExclusiveOwnerThread(Thread.currentThread())将独占线程变量exclusiveOwnerThread指向当前线程 如果修改失败，将会调用acquire(1)尝试重新获取锁。原因是可能当前线程之前通过lock()已经获取到锁了，现在又调用lock(),所以会失败，所以会判断独占锁的线程是否是当前线程。如果不是的话或者重试以后还是没有获取到锁就会将当前线程封装成一个队列节点放到阻塞队列中，挂起当前线程。 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 首先会再调用tryAcquire(arg)尝试通过CAS获取锁 如果获取成功，直接返回 如果获取失败，就会调用addWaiter(Node.EXCLUSIVE), arg)创建队列节点 12345678910111213141516171819202122232425262728293031323334353637public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125;// 获取非公平锁final boolean nonfairTryAcquire(int acquires) &#123; // 获取当前线程 final Thread current = Thread.currentThread(); // 获取锁状态 int c = getState(); // 如果当前锁没有被锁定，就会尝试再次通过CAS获取锁 if (c == 0) &#123; // 如果获取锁成功(通过CAS成功修改state为1)，设置当前线程为独占锁线程 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果已经获取锁的线程再次进入临界区，直接将锁状态加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; // 整数溢出 if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); // 设置锁计数 setState(nextc); return true; &#125; // 尝试获取锁失败，返回false return false;&#125; 将当前线程封装成队列节点，插入到队列尾部 1234567891011121314151617181920212223242526272829303132333435363738394041424344private Node addWaiter(Node mode) &#123; // 定义一个关于当前线程的节点Node Node node = new Node(Thread.currentThread(), mode); // 先通过CAS将当前节点放到队列尾部，如果失败，在执行死循环保证将该节点放到队列尾部 // 优点是：如果成功放到队列尾部，就不用去执行死循环 // Try the fast path of enq; backup to full enq on failure // 获取队尾节点 Node pred = tail; // 如果队列已经存在 if (pred != null) &#123; // 设置当前节点的前驱节点为目前队尾节点 node.prev = pred; // 通过CAS设置tail指向node if (compareAndSetTail(pred, node)) &#123; // 设置tail指向node成功以后，将原来的队尾节点(pred目前指向的节点)后继节点指向node pred.next = node; return node; &#125; &#125; // CAS设置失败，执行死循环保证将封装当前线程的节点放到队列中 enq(node); return node;&#125;// CAS设置失败，执行死循环保证将封装当前线程的节点放到队列中private Node enq(final Node node) &#123; for (;;) &#123; // 获取队尾节点 Node t = tail; // 如果队列还没创建 if (t == null) &#123; // Must initialize // 创建一个虚假节点new Node()队头head和队尾tail都指向该节点 if (compareAndSetHead(new Node())) tail = head; // 队列已经存在：通过CAS将当前节点入队即可 &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 插入到队列以后，根据当前线程节点的前驱节点状态waitstatus决定当前线程是否应该被阻塞 1234567891011121314151617181920212223242526272829final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; // 直到获取锁，才会跳出死循环 for (;;) &#123; // 获取当前节点的前驱节点：为了在锁定之前决定是否会再次去尝试获取锁... final Node p = node.predecessor(); // 如果当前节点的前驱节点是头节点，在锁定之前会再次去尝试获取锁... if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取锁成功以后将此节点设置为头节点(head = node;)，释放线程(node.thread = null;) setHead(node); // 将之前的头节点next指针置空 p.next = null; // help GC failed = false; return interrupted; &#125; // 在挂起当前线程之前，还会再次判断当前线程是否应该阻塞(可能它前面的节点【都】已经取消了呢？(节点处于CANCELL状态)，此时就会返回false) // 如果应该阻塞当前线程，就会调用parkAndCheckInterrupt()阻塞当前线程并检查中断状态 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 封装当前线程的节点会根据它前驱节点的状态判断当前线程是否应该被阻塞 如果当前线程节点的前驱节点状态是SIGNAL(-1)，说明已经可以保证它的前驱节点在释放锁时唤醒它，所以当前线程可以安全的被阻塞了… 如果当前线程节点的前驱节点状态大于0，说明前驱节点封装的线程被取消了，应该从队列中移除，然后判断前驱节点的前驱节点… 直到找到状态为小于0的节点 如果当前线程节点的前驱节点状态等于0，说明前驱节点里的线程已经被阻塞了，此时会将前驱节点的状态改为SIGNAL，然后返回true，代表应该阻塞当前线程 123456789101112131415161718192021222324252627282930private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) // SIGNAL == -1 /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 当前节点的前驱节点已经被取消了(失效了，可能已经为null)，需要重置当前节点的前驱节点。 // 节点操作因为超时或者对应的线程被interrupt。节点不应该留在此状态，一旦达到此状态将从CHL队列中踢出。 if (ws &gt; 0) &#123; // cancelled == 1 &gt; 0 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 当head指向的是一个dummy节点时(当第一个节点插入到CLH队列中时)，ws为0。 需要修改dummy节点的waitstatus compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 挂起当前线程。当此线程被唤醒时判断线程的中断状态，如果线程被中断过，就通过 1if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; 重新设置线程的中断状态 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; unlock()首先将锁计数state减1 如果锁计数state为0了，则释放当前锁，唤醒头节点的下一节点中封装的线程 如果锁计数state不为0，则不释放当前锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public void unlock() &#123; sync.release(1);&#125;// 1. 修改锁计数 2. 唤醒下一节点中封装的线程public final boolean release(int arg) &#123; // 修改锁计数 if (tryRelease(arg)) &#123; Node h = head; // 可能当前线程第一个获取锁的线程，此时head并没有被初始化 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;// 尝试释放：将state减1，根据state的值决定是否应该释放锁protected final boolean tryRelease(int releases) &#123; // 获取释放掉锁以后的锁计数 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果锁计数为0，则释放当前线程持有的锁 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125;// 唤醒下一节点中封装的线程private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ // 获取头节点线程的等待状态为SIGNAL==-1，表示下一节点不用再阻塞 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 下一节点可能已经取消，所以如果下一节点取消的话，就需要找到一个有效的下一节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 唤醒下一节点 if (s != null) LockSupport.unpark(s.thread);&#125; tryLock()如果获取不到锁，直接返回false，不会阻塞当前线程。在tryLock()中尝试获取一次锁，如果没有成功，就不会再去获取或者阻塞当前线程，而是返回false如果获取不到 12345678910111213141516171819202122public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; tryLock(long timeout, TimeUnit unit)超时获取锁：在指定时间段内timeout会一直尝试获取锁，直到获取锁返回true，如果一直没有获取锁，超时以后会返回false 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125;public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 先尝试获取一次，如果失败，再执行超时获取 return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125;private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; // 获取超时时间 final long deadline = System.nanoTime() + nanosTimeout; // 将当前线程封装成节点添加到队列中 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; // 死循环中尝试多次获取。注意：如果获取不到，就会阻塞线程【指定】时间。 for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); // 如果超时，直接返回false，代表没有获取到锁 if (nanosTimeout &lt;= 0L) return false; // 如果队列中有等待线程，此时应该阻塞当前线程【一段时间】 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; lockInterruptibly()支持中断锁：如果一个线程在获取锁的过程中被中断了，会抛出InterruptedException。Java Doc： If the current thread:has its interrupted status set on entry to this method; oris interrupted while acquiring the lock,then InterruptedException is thrown and the current thread’s interrupted status is cleared. 123456789101112131415161718192021222324252627282930313233343536public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125;public final void acquireInterruptibly(int arg) throws InterruptedException &#123; // 如果当前线程设置了中断，直接向上抛异常，并且清除中断状态，不会再去获取锁。 if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125;private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; // 被阻塞的线程唤醒之后：如果检查到当前线程设置了中断，直接抛异常不会再去尝试获取锁 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 公平锁 new ReentrantLock(true);lock()公平锁获取锁的过程: 首先会根据锁状态state来判断是否应该获取锁，而不是直接像非公平锁那样，直接尝试通过CAScompareAndSetState(0, 1)设置为独占模式(修改为1)来获取锁。 如果此时可以获取锁(state为0)，会进一步判断等待队列中是否存在等待获取锁的线程(和非公平锁的区别) 如果此时队列中有等待线程，就会直接挂起当前线程。 如果此时队列中没有等待线程，就会尝试通过CAScompareAndSetState(0, acquires)去尝试获取锁。 如果修改成功，将会调用setExclusiveOwnerThread(Thread.currentThread())将独占线程变量exclusiveOwnerThread指向当前线程 如果修改失败，将会调用acquire(1) 如果此时不可以获取锁(state不为0)，直接挂起当前线程。 注意：公平锁和非公平锁都重写了tryAcquire(int acquires) 1234567891011121314151617181920212223242526272829303132333435363738394041424344final void lock() &#123; acquire(1);&#125;public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 判断锁状态，是否可以获取 if (c == 0) &#123; // 如果此时可以获取锁，会进一步判断等待队列中是否有线程正在等待获取锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 判断此次是否是重入，如果重入，直接将锁计数加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; // 即：不能获取锁 return false;&#125;// 判断队列中是否还存在因为没有获取到锁而被阻塞的线程public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // 如果h.next == null，说明其它线程刚创建了一个dummy节点，还没入队，并且此时tail为null，head指向dummy节点 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; Q&amp;A公平锁和非公平锁区别？ 处于非公平锁的线程直接尝试获取锁，不会去判断等待队列中是否已经有线程正在等待锁的释放。非公平锁会导致线程饥饿现象 处于公平锁模式的线程按照请求锁的顺序决定获取锁的顺序(加锁时会判断等待队列中是否已经有线程正在等待锁，如果有的话就不会再去获取锁而是插到队列尾部)。 ReentrantLock和synchronized的区别？ 在用法上 ReentrantLock需要显示的获取锁和释放锁。(注意：为了安全，需要在finally中释放锁)。而synchronized会自动地获取锁和释放锁 ReentrantLock通过Condition实现了唤醒线程和使当前线程睡眠的API，没有使用Object的API。 ReentrantLock只能修饰代码块，并不能修饰方法。而synchronized既可以修饰方法也可以修饰代码块 在特性上 ReentrantLock可以以非阻塞的形式来获取锁，如果没有获取锁，会返回false，而不会阻塞当前线程。 synchronized如果没有获取到锁，会阻塞当前线程 ReentrantLock可以以超时的形式来获取锁，如果在指定时间段内没有获取到锁，直接返回false，不会阻塞当前线程。 ReentrantLock实现了公平锁，防止了非公平锁可能产生的线程饥饿现象。 ReentrantLock实现了以中断形式来获取锁，如果线程在获取锁的过程中，被中断了，会直接抛出异常，不会再去尝试获取锁。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C源码阅读笔记（三）同步器]]></title>
    <url>%2F2018%2F08%2F14%2FSynchronizer%2F</url>
    <content type="text"><![CDATA[同步器用来协助线程同步，具体有 CountDownLatch、CyclicBarrier、Semaphore、Exchanger。 CountDownLatch通俗理解: CountDownLatch可以理解为是一扇门，门上有若干把锁，当线程到达这个门时，如果门上锁的数量不为0，就会阻塞当前线程，直到门上锁的数量减为0，此时会唤醒被阻塞的线程。并且门打开以后不会在关闭。具体实现: CountDownLatch是基于AQS实现的，锁的数量就是AQS中的state，通过构造函数设置state初始值。当调用CountDownLatch的await()方法时，如果state不为0，就会阻塞当前线程。如果为0就不会阻塞。当通过countDown()将state减为0时，就会唤醒之前被阻塞的线程。并且state减为0后不会被重置。CountDownLatch可以理解为:所有线程需要等待某个事件发生以后，才能继续执行，否则就会被阻塞。 部分源码分析public CountDownLatch(int count)通过构造函数设置锁的初始数量，也就是AQS里的state 123456789public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException("count &lt; 0"); this.sync = new Sync(count);&#125;// 设置AQS中的state，Sync继承了AQSSync(int count) &#123; setState(count);&#125; public void await()会判断state(锁)的数量是否为0，如果不为0就会被阻塞。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 获取共享模式下的锁，当state不为0时tryAcquireShared(arg)会返回-1 =&gt; 代表获取锁失败(具体到CountDownLatch，就是等待的事件没有发生)需要被阻塞。否则返回1 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;// 当锁的数量(state)不为0时，返回-1protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 将节点添加到队列中 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 前驱节点为头节点 if (p == head) &#123; // 再次尝试获取共享锁(判断锁的数量是否为0了) int r = tryAcquireShared(arg); // 如果锁的数量为0了，就会进这个if if (r &gt;= 0) &#123; // 设置当前节点为头节点，并且唤醒后继节点 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 判断是否阻塞当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; public void countDown()释放锁(将state减1) 123456789101112131415161718192021222324public void countDown() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; // 判断将state减1后是否为0，如果为0，则唤醒被阻塞的线程 if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; doReleaseShared()12345678910111213141516171819202122232425262728private void doReleaseShared() &#123; for (;;) &#123; Node h = head; // h == null 代表还没有线程被阻塞，也就是说没有添加到阻塞队列里，所以不用唤醒 // h == tail 代表state == 0了，但是又一个线程之前判断state不为0，正在创建head节点， // 也不用管(因为执行 int r = tryAcquireShared(arg); 时，state为0，所以就会返回) if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 因为释放了后继节点以后，后继节点对应线程执行setHeadAndPropagate(node, r)会修改head指针 // 当前节点中的线程执行最后一个 if(h == head)时，可能后继节点中的线程已经修改了head， 判断false后当前节点中的线程就会重新循环 // 所以当前节点对应的线程以及后继节点对应的线程同时走到这里后，并发修改head节点的waitstatus就可能会失败 // 为什么要这样，不太清楚。有博客说是为了提高吞吐量。也就说当前线程唤醒了后继节点中的线程后，还可能会帮助唤醒其它节点中的线程 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒头节点head的后继节点 unparkSuccessor(h); &#125; // 当前节点的waitStatus为0， 是因为之前只有当前节点被阻塞，当前节点修改时，有新的节点入队了，此时需要被唤醒，所以当前线程就会重新进入循环。 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 返回false后，代表由当前节点对应线程唤醒的后继节点中的线程修改了head指针，导致返回false if (h == head) // loop if head changed break; &#125;&#125; 应用场景 统计多个线程并发执行某个任务所需要的时间。首先是要保证所有线程都处于就绪状态。也就是说线程需要等待【所有线程都处于就绪状态】这个事件发生。然后并发执行任务。12345678910111213CountDownLatch startSignal = new CountDownLatch(1);CountDownLatch doneSignal = new CountDownLatch(N); // N代表N个线程ExecutorService threadPool = Executors.newFixedThreadPool(N);for (int i = 0; i &lt; N; i++) threadPool.submit(()-&gt;&#123; startSignal.await(); // 等待【所有线程就绪】事件发生 doTask(); doneSignal().countDown(); &#125;);long startTime = System.currentTimeMillis();startSignal.countDown(); // 此时所有线程已经就绪，然后触发【所有线程就绪】事件发生doneSignal().await(); // 等待【所有线程执行完毕】这个事件发生long total = System.currentTimeMillis(); - startTime; // 统计时间 CyclicBarrierCyclicBarrier循环_栅栏(障碍物)。直到所有线程都到达以后，才会唤醒线程，否则提前到达的线程会被阻塞。当唤醒所有被阻塞的线程以后，会进入下一代，并且重置障碍，达到循环(Cyclic)的目的。CyclicBarrier可以理解为：等待所有线程都到达以后，被阻塞的线程才能继续执行。CyclicBarrier并没有直接依赖AQS实现，具体是通过ReentrantLock和Condition做的实现，因为要并发修改等待的线程数量。 部分源码解析public CyclicBarrier(int parties)parties是需要等待的线程的数量，当等待的线程数量达到parties时，会唤醒这些等待的线程。barrierAction是当最后一个线程到达栅栏时，需要执行的操作。count是还需要等待几个线程，当需要等待的线程数量为0时，表示可以唤醒等待的线程 12345678910public CyclicBarrier(int parties) &#123; this(parties, null);&#125;public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125; public int await()将需要等待的线程数量减1，当减到0时就会唤醒所有等待的线程。等待所有的线程到达，如果当前线程不是最后一个到达的，将会被阻塞，直到最后一个线程到达后被唤醒。具体的执行逻辑在dowait(boolean timed, long nanos)里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 获取当前分代 final Generation g = generation; // 判断当前分代是否由于超时、中断等被打破 if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; // 判断还需要等待的线程的数量 int index = --count; // 如果需要等待的线程的数量为0，则表明当前线程是最后一个线程 // 判断是否需要执行barrierCommand，然后唤醒等待的线程 if (index == 0) &#123; // tripped boolean ranAction = false; try &#123; // 获取注册的操作 final Runnable command = barrierCommand; // 如果操作不为null，则执行run() if (command != null) command.run(); ranAction = true; // 进入下一分代，重置count nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; // loop until tripped, broken, interrupted, or timed out // 如果当前线程不是最后一个线程，将会被阻塞 for (;;) &#123; try &#123; // 没有设置超时等待，直接阻塞 if (!timed) trip.await(); // 设置了超时等待，则等待指定时间 else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; // 如果线程被中断了， 需要打破分代(设置Generation标志位) if (g == generation &amp;&amp; ! g.broken) &#123; // 设置标志位、唤醒等待的线程 breakBarrier(); throw ie; &#125; else &#123; // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // "belong" to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; // 当被唤醒的线程，发现分代被打破以后，直接抛出异常 if (g.broken) throw new BrokenBarrierException(); // 当被唤醒的线程，发现当前分代不等于新的分代(最后一个线程会重新创建generation进入下一分代)。直接返回 if (g != generation) return index; // 如果超时以后，直接打破分代、并且抛出超时异常。 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; private void nextGeneration()唤醒等待的线程，重置count，进入下一分代 1234567private void nextGeneration() &#123; // signal completion of last generation trip.signalAll(); // set up next generation count = parties; generation = new Generation();&#125; private void breakBarrier()打破分代，重置count，并且唤醒其他线程。 12345private void breakBarrier() &#123; generation.broken = true; count = parties; trip.signalAll();&#125; 应用场景 将大任务分解成若干个子任务。现在要统计一个矩阵所有元素相加和。可以让每一个线程求每一行。最后一个线程执行完以后，调用await()执行之前注册的barrierCommand将每一个线程的结果汇总。代码来自Oracle doc 123456789101112131415161718192021222324252627282930class Solver &#123; final int N; final float[][] data; final CyclicBarrier barrier; class Worker implements Runnable &#123; int myRow; Worker(int row) &#123; myRow = row; &#125; public void run() &#123; while (!done()) &#123; processRow(myRow); try &#123; barrier.await(); &#125; catch (InterruptedException ex) &#123; return; &#125; catch (BrokenBarrierException ex) &#123; return; &#125; &#125; &#125; &#125; public Solver(float[][] matrix) &#123; data = matrix; N = matrix.length; barrier = new CyclicBarrier(N, () -&gt; &#123;mergeRows(...);&#125;); for (int i = 0; i &lt; N; ++i) new Thread(new Worker(i)).start(); &#125;&#125; 可以让固定数量的线程周期性的执行任务。比如周期性每次让10个线程并发执行 12345678910111213141516CyclicBarrier cyclicBarrier = new CyclicBarrier(times, ()-&gt; &#123; System.out.println("================");&#125;);for (int i = 0; i &lt; 10; i++) &#123; new Thread(()-&gt; &#123; try &#123; while (true) &#123; cyclicBarrier.await(); // do something System.out.println(Thread.currentThread().getName()); &#125; &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;).start();&#125; Semaphore Semaphore可以理解为是一个资源池，线程需要从这个资源池中申请到资源才能继续运行，否则会被阻塞直到资源池中有可用资源。 Semaphore是基于AQS实现的，和CountDownLatch类似。CountDownLatch是当state为0时，需要唤醒线程。而它将AQS中的state表示为可用的资源数量，当state为0时代表没有可用资源，会将阻塞当前线程，将其添加到队列中，当其它线程释放资源后，此时state不为0，就会唤醒所有的被阻塞的线程。 部分源码分析public void acquire(int permits)非公平信号量获取许可过程：通过final int nonfairTryAcquireShared(int acquires)获取state值，判断是否还有可用的许可。 如果有的话直接返回 如果没有可用的许可，将当前线程封装到队列中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public void acquire(int permits) throws InterruptedException &#123; // 传入的许可数量是负数，抛异常 if (permits &lt; 0) throw new IllegalArgumentException(); // 尝试获取许可 sync.acquireSharedInterruptibly(permits);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 判断可用的许可数量是否满足需要，如果不满足会将当前线程封装到队列中 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);&#125; final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; // 获取可用的许可 int available = getState(); // 判断可用许可数量是否满足需要 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 将节点添加到队列中 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 前驱节点为头节点 if (p == head) &#123; // 再次尝试获取共享锁(判断锁的数量是否为0了) int r = tryAcquireShared(arg); // 如果锁的数量为0了，就会进这个if if (r &gt;= 0) &#123; // 设置当前节点为头节点，并且唤醒后继节点 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 判断是否阻塞当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; public void release()释放许可操作：将状态变量state加1，并唤醒阻塞的线程。注意(Java Doc)：在释放许可时，不必提前获取许可 There is no requirement that a thread that releases a permit must have acquired that permit by calling acquire. Correct usage of a semaphore is established by programming convention in the application. 1234567891011121314151617181920212223public void release() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; // 释放资源以后，唤醒之前被阻塞的所有线程，让它们竞争资源 if (tryReleaseShared(arg)) &#123; // 参照CountDownLatch注释 doReleaseShared(); return true; &#125; return false;&#125;// 通过CAS将state加1，因为释放操作是多个线程并发的。protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); if (compareAndSetState(current, next)) return true; &#125;&#125; 应用场景互斥锁当维护的许可数量是1时，就是互斥锁 1Semaphore mutex = new Semaphore(1); 控制线程提交的最大任务量比如爬虫程序中，控制线程提交的最大任务量，将许可数量设置为线程池中最大线程数量 + 任务队列长度来保证提交的任务都能被执行，防止提交任务过多导致内存溢出或者执行拒绝策略。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C源码阅读笔记（二）并发容器]]></title>
    <url>%2F2018%2F08%2F12%2FSynchronizedContainer%2F</url>
    <content type="text"><![CDATA[并发容器提供了线程安全的容器。比如线程安全的Map/Queue/List (ConcurrentHashMap、BlockingQueue、CopyOnWriteArrayList)，其它的还有阻塞队列，比如ArrayBolckingQueue、LinkedBlockingQueue、DelayQueue、SynchronousQueue ConcurrentHashMap12public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable 介绍ConcurrentHashMap是一个线程安全的Map 部分源码分析public V put(K key, V value)调用putVal(K key, V value, boolean onlyIfAbsent) 123public V put(K key, V value) &#123; return putVal(key, value, false);&#125; JDK8在插入的时候会对数据进行预判断，不允许key和value为null，否则抛空指针。由于内部维护的数组tab是懒加载，当tab没初始化时，会将tab初始化。通过轮询由volatile修饰的变量来保证只能有一个线程初始化数组。当哈希表正在进行扩容时，当前线程会尝试帮助扩容。因为在扩容时会将ForwardingNode 放到数组下标，而ForwardingNode的hash为MOVED。插入以后会将记录键值对数量的值尝试用CAS加1，如果没有成功，就将这个变化值存到一个数组中。最终键值对的数量是记录键值对数量的值加上记录变化的数组中的值。扩容时会将原哈希表中的键值对放到一个大小是原哈希表二倍的新的哈希表中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // 预处理 if (key == null || value == null) throw new NullPointerException(); // 为了分布均匀对key的hashcode再hash int hash = spread(key.hashCode()); // 根据binCount通过计算链表长度，判断链表是否修改过，如果链表的数量超过设定的阈值，插入完成之后需要变成红黑树 int binCount = 0; // 初始化tab，死循环直到插入成功 for (Node&lt;K,V&gt;[] tab = table;;) &#123; // 指向目标节点 Node&lt;K,V&gt; f; int n, i, fh; // 延迟加载:如果没有初始化进行初始化，并且通过轮询volatile变量保证只有一个线程执行哈希表的初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 如果数组下标对应的元素为null，通过CAS放到当前数组下标处 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 如果当前节点的hash值为MOVED常量，则表示这个ConcurrentHashMap正在进行扩容 // (在转移当前桶时，将将当前数组下表设置为ForwardingNode) // ForwardingNode的Hash等于MOVED: super(MOVED, null, null, null); else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); // 当前数组下标有元素，并且可以正常插入，则根据节点元素类型是红黑树节点还是链表节点然后执行插入 else &#123; V oldVal = null; // 加锁，Monitor对象是当前数组下标元素持有的Monitor synchronized (f) &#123; // tabAt(tab,i)会通过Unsafe类求出数组下标元素，再次判断确保是否是上面所确定的f if (tabAt(tab, i) == f) &#123; // 代表是链表元素，执行插入链表操作 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 如果已经存在此key，则更新即可(此处为了性能，尽量不用equals()，所以显示比较是否指向同一个对象) if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; // 不存在，则插入到链表尾部 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 当前数组下标元素类型是红黑树,执行红黑树插入操作 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 根据binCount判断链表元素个数 if (binCount != 0) &#123; // 超过阈值，则将链表变成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 将当前维护的baseCount + 1，然后判断是否需要扩容 addCount(1L, binCount); return null;&#125;/* 下面两个函数来源: https://yfzhou.coding.me/2018/12/24/%E5%89%91%E6%8C%87ConcurrentHashMap%E3%80%90%E5%9F%BA%E4%BA%8EJDK1-8%E3%80%91/ */ // 经过一系列的判断，如果可以帮助扩容的话，最终会调用transfer(tab, nextTab);协助扩容final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; // 如果 table 不是空 且 node 节点是转移类型，数据检验 // 且 node 节点的 nextTable（新 table） 不是空，同样也是数据校验 // 尝试帮助扩容 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; // 根据 length 得到一个标识符号 int rs = resizeStamp(tab.length); // 如果 nextTab 没有被并发修改 且 tab 也没有被并发修改 // 且 sizeCtl &lt; 0 （说明还在扩容） while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; // 如果 sizeCtl 无符号右移 16 不等于 rs （ sc前 16 位如果不等于标识符，则标识符变化了） // 或者 sizeCtl == rs + 1 （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1） // 或者 sizeCtl == rs + 65535 （如果达到最大帮助线程的数量，即 65535） // 或者转移下标正在调整 （扩容结束） // 结束循环，返回 table if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // 如果以上都不是, 将 sizeCtl + 1, （表示增加了一个线程帮助其扩容） if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; // 进行转移，将table指向的tab中的键值对重新放到nextTab中(nextTab容量是tab的二倍)，扩容完毕后，将table指向nextTab transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125;// 从 putVal 传入的参数是 1， binCount，binCount 默认是0，只有 hash 冲突了才会大于 1.且他的大小是链表的长度（如果不是红黑数结构的话）。private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; // 如果CounterCell不为null，就将这次变化的值放到CounterCell,否则尝试用CAS更新baseCount，如果更新失败，就将这次变化的值放到CountCell中 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // 如果CAS更新CounterCell失败，就会进入这个方法，保证最终更新成功 fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; //如果需要检查,检查是否需要扩容，在 putVal 方法调用时，默认就是要检查的。 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; // 如果map.size() 大于 sizeCtl（达到扩容阈值需要扩容） 且 // table 不是空；且 table 的长度小于 1 &lt;&lt; 30。（可以扩容） while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; // 根据 length 得到一个标识 int rs = resizeStamp(n); // 如果正在扩容 if (sc &lt; 0) &#123; // 如果 sc 的低 16 位不等于标识符（校验异常 sizeCtl 变化了） // 如果 sc == 标识符 + 1 （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1） // 如果 sc == 标识符 + 65535（帮助线程数已经达到最大） // 如果 nextTable == null（结束扩容了） // 如果 transferIndex &lt;= 0 (转移状态变化了) // 结束循环 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果可以帮助扩容，那么将 sc 加 1. 表示多了一个线程在帮助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) // 扩容 transfer(tab, nt); &#125; // 如果不在扩容，将 sc 更新：标识符左移 16 位 然后 + 2. 也就是变成一个负数。高 16 位是标识符，低 16 位初始是 2. else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) // 更新 sizeCtl 为负数后，开始扩容。 transfer(tab, null); s = sumCount(); &#125; &#125;&#125; JDK7不允许value为null 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public V put(K key, V value) &#123; Segment&lt;K, V&gt; s; // 不允许value为null if (value == null) throw new NullPointerException(); int hash = hash(key); // UNSAFE通过hash找到Segment int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K, V&gt;) UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); return s.put(key, hash, value, false);&#125;final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; // 加锁，如果加锁成功则执行后续操作，没有竞争到锁就需要自旋直到获取到锁并执行插入操作(自旋一定次数，就会调用阻塞锁)。 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; // 找到引用的数组 HashEntry&lt;K,V&gt;[] tab = table; // 求模计算数组下标 int index = (tab.length - 1) &amp; hash; // 找到数组第一个元素 HashEntry&lt;K,V&gt; first = entryAt(tab, index); // 死循环，直到插入成功 for (HashEntry&lt;K,V&gt; e = first;;) &#123; // 数组对应下标已经存在数值。 if (e != null) &#123; K k; // 已经存在此key，进行更新 if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; // 记录每一个Segment中的HashEntry数组中元素的数量 ++modCount; &#125; break; &#125; e = e.next; // 如果当前数组下标已经存在元素 &#125; else &#123; // 当前线程可能自旋过（自旋过程可能会返回一个已经初始化的node），所以需要判断node是否为null if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; // 判断是否需要扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; // 释放锁 unlock(); &#125; return oldValue;&#125; public V get(Object key)JDK8计算key对应的hash，然后通过hash定位到具体的桶，然后找到具体的value，因为value由volatile修饰，所以可以保证拿到的是最新的value 12345678910111213141516171819202122public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 在红黑树中查找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 在链表中查找 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; JDK71234567891011121314151617public V get(Object key) &#123; Segment&lt;K, V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K, V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; // 通过UNSAFE获取Segment，通过Segment获取HashEntry数组引用，进而找到指定的key if ((s = (Segment&lt;K, V&gt;) UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K, V&gt; e = (HashEntry&lt;K, V&gt;) UNSAFE.getObjectVolatile (tab, ((long) (((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; public int size()JDK8通过由volatile修饰的baseCount变量以及CounterCell对象记录变化的次数求出size() 123456public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125; 12345678910111213final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; // 获取baseCount long sum = baseCount; if (as != null) &#123; // 循环遍历每一个CountCell中的value for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; JDK7通过计算Segment数组中每一个Segment中的modcount(在put时会++modCount)求出sum。但是不止求一次sum，会至少求两次（由RETRIES_BEFORE_LOCK决定的），如果两次求出的sum不一致，下次求就会将Segment数组全部加锁，重新求一次。 123456789101112131415161718192021222324252627282930313233343536373839404142public int size() &#123; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K, V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try &#123; for (; ; ) &#123; // 超出两次，将Segment全部加锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K, V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; // 获取Segment对象的modCount sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 和上一次求的结果比较 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; Q&amp;AJDK8和JDK7的区别？存储结构 JDK8存储结构采用Node类型数组加链表并通过拉链法解决hash冲突而JDK7基于AQS实现了一个Segment类继承自ReentrantLock，每个Segment对象持有一个HashEntry数组。Node和HashEntry都是实现了Map.Entry接口，只不过名字不同。 并发更新操作的实现 JDK8通过synchronized+CAS机制进行并发更新，锁对象是数组下标对应的元素持有的Monitor。JDK7继承了AQS里的ReentrantLock进行加锁实现的并发更新。 计算size JDK8通过维护一个由volatile修饰的baseCount变量进行计数，以及一个CounterCell类进行记录变化的次数来确定size。JDK7采用延迟计算，在计算过程中会对每个Segment计算至少两次，如果出现数据不一致现象就进行全部加锁最后求得size。 参考 ConcurrentHashMap 源码解读 剑指ConcurrentHashMap【基于JDK1.8】 谈谈ConcurrentHashMap1.7和1.8的不同实现 ConcurrentHashMap源码分析(JDK1.8) ConcurrentHashMap实现原理及源码分析 BlockingQueue BlockingQueue接口下有ArrayBolckingQueue、LinkedBlockingQueue、DelayQueue、SynchronousQueue、PriorityQueue直接实现 BlockingDeque接口继承自BlockingQueue下面有LinkedBlockingDeque实现 ArrayBlockingQueueArrayBlockingQueue内部维护了一个ReentrantLock以及两个和ReentrantLock有关的Condition对象来实现阻塞操作。整体是一个循环队列(基于数组实现),并且队列的长度一旦设定就不可在变。 1public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable 部分源码分析下面说的非阻塞/阻塞操作都是指已经获取锁后的操作 变量 final Object[] items; // 存放元素的数组 int takeIndex; // 队头元素位置 int putIndex; // 队尾元素位置 int count; // 队列长度 public ArrayBlockingQueue(int capacity)构造函数必须指定容量，并且容量后期不可扩充，如果队列满了以后会直接阻塞当前线程 123public ArrayBlockingQueue(int capacity) &#123; this(capacity, false); &#125; public boolean add(E e)非阻塞的入队方法，如果返回false则代表添加失败，父类会调用子类的offer(e) 12345678910111213141516171819202122232425262728293031323334353637public boolean add(E e) &#123; return super.add(e);&#125;public boolean offer(E e) &#123; // 队列不允许添加null，如果添加null直接抛出异常 checkNotNull(e); final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 如果队列已满，则返回false if (count == items.length) return false; // 否则入队，返回true代表入队成功 else &#123; enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; // 将入队元素放在入队位置 items[putIndex] = x; // 如果入完队以后队列已经满了，则将putIndex放到初始位置0 // 因为用了一个冗余变量count来记录队列中元素的数量，所以不必再空一个元素来判断队列满或者队列空 if (++putIndex == items.length) putIndex = 0; // 增加队列数量 count++; // 唤醒因为出队时队列没有元素而被阻塞的线程 notEmpty.signal();&#125; public boolean offer(E e, long timeout, TimeUnit unit)如果当前队列已经满了，则等待timeout，单位是unit，超时以后如果当前队列还是满的，则返回false 1234567891011121314151617181920212223public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; // 提前判空 checkNotNull(e); // 将超时时间换成纳秒 long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; // 判断队列长度 while (count == items.length) &#123; // 超时以后，如果当前队列还是满的，则返回false if (nanos &lt;= 0) return false; // 阻塞当前线程nanos时间 nanos = notFull.awaitNanos(nanos); &#125; // 正常入队 enqueue(e); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; public boolean offer(E e)以阻塞的形式入队，如果当前队列已满则阻塞当前线程，并且采用可中断锁。 123456789101112131415public void put(E e) throws InterruptedException &#123; // 提前判空 checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; // 如果队列已满，则阻塞当前线程 while (count == items.length) notFull.await(); // 否则入队 enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; public E poll()非阻塞的出队操作，如果当前队列长度为0则返回false，否则返回false 12345678910111213141516171819202122232425262728293031public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings("unchecked") // 获取要出队的元素 E x = (E) items[takeIndex]; // 将出对元素的值设为null items[takeIndex] = null; // 实现循环队列 if (++takeIndex == items.length) takeIndex = 0; // 修改队列长度 count--; // 迭代器相关操作 if (itrs != null) itrs.elementDequeued(); // 唤醒当队列满时，因为入队操作而被阻塞的线程 notFull.signal(); // 返回出队元素 return x;&#125; public E take() throws InterruptedException以阻塞形式出队，如果当前队列长度为0，则阻塞当前线程 12345678910111213public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; // 如果队列长度为0，阻塞当前线程 while (count == 0) notEmpty.await(); // 队列中存在元素，正常出队 return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; public E poll(long timeout, TimeUnit unit) throws InterruptedException以超时的形式出队，如果当前队列长度为0，则阻塞当前线程一段时间，超时以后如果当前队列仍然没有元素，则返回false，否则正常出队。 123456789101112131415public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) &#123; if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); &#125; return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; public E peek()获取队头元素 123456789101112public E peek() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return itemAt(takeIndex); // null when queue is empty &#125; finally &#123; lock.unlock(); &#125;&#125;final E itemAt(int i) &#123; return (E) items[i];&#125; public int size()获取队列中的元素数量，获取数量前加锁，保证获取到的数量是最新的 个人认为：去掉lock，用volatile修饰count也可以获取最新的正确的元素数量，因为每次对count的修改最多只是一个线程。去掉lock以后，保证每次读取count是最新的即可。 123456789public int size() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return count; &#125; finally &#123; lock.unlock(); &#125;&#125; public int remainingCapacity()获取队列的剩余空间(还可以存放多少元素)，不能通过判断剩余空间数量来决定是否插入，因为判断 -&gt; 插入是非原子操作。 12345678910public int remainingCapacity() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 队列中数组的长度 - 队列中的元素数量 return items.length - count; &#125; finally &#123; lock.unlock(); &#125;&#125; public boolean remove(Object o)移除队列中的元素 1234567891011121314151617181920212223242526272829public boolean remove(Object o) &#123; if (o == null) return false; final Object[] items = this.items; final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 预判断队列中的元素数量 if (count &gt; 0) &#123; // 获取下一个要插入元素的位置 final int putIndex = this.putIndex; // 获取队头元素位置 int i = takeIndex; do &#123; // 找到目标元素 if (o.equals(items[i])) &#123; // 移除队列中下标为i的元素 removeAt(i); return true; &#125; // 保证循环 if (++i == items.length) i = 0; &#125; while (i != putIndex); // 到达队尾 &#125; return false; &#125; finally &#123; lock.unlock(); &#125;&#125; CopyOnWriteArrayList12public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable CopyOnWriteArrayList是一个线程安全的List,顾名思义，写时复制。当对数组做修改操作时，会加锁。比如添加元素时，会先将原数组元素拷贝到一个新的更大的数组中，将元素添加到新数组中，然后将原数组引用指向新数组。又因为数组由volatile修饰，所以对原数组引用的修改对其它线程是可见的。相对于Vector效率更高。 部分源码分析public boolean add(E e)当添加元素时，需要加锁保证线程安全，修改完以后将原数组引用指向新数组。 12345678910111213141516171819public boolean add(E e) &#123; final ReentrantLock lock = this.lock; // 修改之前先获取锁 lock.lock(); try &#123; // 获取原数组引用 Object[] elements = getArray(); int len = elements.length; // 将原数组元素复制到更大的新数组中 Object[] newElements = Arrays.copyOf(elements, len + 1); // 向新数组中添加元素 newElements[len] = e; // 将原数组引用指向新数组 setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; public E set(int index, E element)修改指定下标的元素。当修改元素时，需要加锁保证线程安全。修改完以后将原数组引用指向新数组。 123456789101112131415161718192021222324public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; Object[] elements = getArray(); // 获取要修改的元素 E oldValue = get(elements, index); // 如果要修改的元素和预期元素值不同 =&gt; 正常修改 if (oldValue != element) &#123; int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; setArray(newElements); // 如果要修改的元素的值和预期元素相同 =&gt; 保持不动即可：将原数组引用指向原数组。 &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; public E get(int index)获取指定下标的元素。因为数组由volatile修饰，所以保证其它线程访问数组时都是最新的。 private transient volatile Object[] array; 123456public E get(int index) &#123; return get(getArray(), index);&#125;private E get(Object[] a, int index) &#123; return (E) a[index];&#125; public E remove(int index)删除指定下标的元素。先获取锁。分删除最后一个元素还是中间元素。当删除最后一个元素，将原数组的将n-1个元素拷贝到新数组中，然后将原数组引用指向新数组即可。当删除的是中间元素。分别将原数组中间元素的左侧元素和右侧元素拷贝到新数组。 1234567891011121314151617181920212223242526public E remove(int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; // 删除的是最后一个元素 if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); // 删除的元素是中间元素 else &#123; Object[] newElements = new Object[len - 1]; // 将要删除元素左侧元素放到新数组中的左侧 // 第二个参数是从原数组的起始位置开始拷贝，第三个是从新数组的起始位置开始放，第四个是要拷贝的元素长度 System.arraycopy(elements, 0, newElements, 0, index); // 将要删除元素右侧元素放到新数组的右侧 System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; Q&amp;ACopyOnWriteArrayList 和 Vector区别？Vector是对每个方法加锁，导致并发效率低，而COWL只对修改操作进行了加锁操作，只读操作并没有加锁。很适合读多写少的应用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C源码阅读笔记（一）AQS]]></title>
    <url>%2F2018%2F08%2F11%2Faqs%2F</url>
    <content type="text"><![CDATA[AQS(AbstractQueuedSynchronizer)这个类提供了一个框架用来实现阻塞锁和一些同步工具类。比如ReentrantLock、ReadWriteLock、Semaphore、CountDownLatch、CyclicBarrier等。 AQS123public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable 介绍这个类通过维护一个volatile修饰的变量state表示锁的获取情况以及一个FIFO队列用来封装要阻塞的线程。线程通过CAS来修改state来获取锁，如果获取失败，会将当前线程封装成队列节点入队或者返回失败(tryLock())。 1234567while(synchronization state does not allow acquire)&#123; enqueue current thread if not already queued; possibly block current thread;&#125; 队列中的每个节点都封装了一个没有获取到锁而被阻塞的线程，队列中的节点有多种状态,比如SIGNAL代表当前节点的后继节点被阻塞了，当释放锁时需要唤醒后继节点中的线程。CANCELLED表示当前节点中的线程超时或者被中断了，此时就会将节点的waitStatus改为CANCELLED。保证出队和入队线程安全用的锁是CLH锁，CLH是一种基于链表的高性能自旋锁。作者介绍说CLH锁相对于MCS锁比较容易处理节点的超时和取消状态。并且出队和入队由于没有锁操作,效率会更高一些。 However, they appeared more amenable than MCS for use in the synchronizer framework because they are more easily adapted to handle cancellation and timeouts, so were chosen as a basis. Among the advantages of CLH locks are that enqueuing and dequeuing are fast, lock-free, and obstruction free (even under contention, one thread will always win an insertion race so will make progress); that detecting whether any threads are waiting is also fast (just check if head is the same as tail); and that release status is decentralized, avoiding some memory contention 12345678910111213141516171819202122232425262728293031323334/*** Status field, taking on only the values:* SIGNAL: The successor of this node is (or will soon be)* blocked (via park), so the current node must* unpark its successor when it releases or* cancels. To avoid races, acquire methods must* first indicate they need a signal,* then retry the atomic acquire, and then,* on failure, block.* CANCELLED: This node is cancelled due to timeout or interrupt.* Nodes never leave this state. In particular,* a thread with cancelled node never again blocks.* CONDITION: This node is currently on a condition queue.* It will not be used as a sync queue node* until transferred, at which time the status* will be set to 0. (Use of this value here has* nothing to do with the other uses of the* field, but simplifies mechanics.)* PROPAGATE: A releaseShared should be propagated to other* nodes. This is set (for head node only) in* doReleaseShared to ensure propagation* continues, even if other operations have* since intervened.* 0: None of the above** The values are arranged numerically to simplify use.* Non-negative values mean that a node doesn't need to* signal. So, most code doesn't need to check for particular* values, just for sign.** The field is initialized to 0 for normal sync nodes, and* CONDITION for condition nodes. It is modified using CAS* (or when possible, unconditional volatile writes).*/ 参考 https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/AbstractQueuedSynchronizer.html http://gee.cs.oswego.edu/dl/papers/aqs.pdf http://www.blogjava.net/xylz/archive/2010/07/06/325390.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C源码阅读笔记（零）java.util.concurrent]]></title>
    <url>%2F2018%2F08%2F10%2Fjuc%2F</url>
    <content type="text"><![CDATA[java.util.concurrent是自JDK1.5提供的一个并发工具包。 J.U.C 框架包含的内容有(以下内容转自这里!!!)： Executor 框架（线程池、Callable、Future），任务的执行和调度框架； AbstractQueuedSynchronizer（AQS框架），J.U.C 中实现锁和同步机制的基础； Locks &amp; Condition（锁和条件变量），比 synchronized、wait、notify 更细粒度的锁机制； Synchronizers（同步器），主要用于协助线程同步，有 CountDownLatch、CyclicBarrier、Semaphore、Exchanger； Atomic Variables（原子变量），方便程序员在多线程环境下，无锁的进行原子操作，核心操作是 CAS 原子操作，所谓的 CAS 操作，即 compare and swap，指的是将预期值与当前变量的值比较(compare)，如果相等则使用新值替换(swap)当前变量，否则不作操作； BlockingQueue（阻塞队列），阻塞队列提供了可阻塞的入队和出对操作，如果队列满了，入队操作将阻塞直到有空间可用，如果队列空了，出队操作将阻塞直到有元素可用； Concurrent Collections（并发容器），说到并发容器，不得不提同步容器，在 JDK1.5 之前，为了线程安全，我们一般都是使用同步容器，同步容器主要的缺点是：对所有容器状态的访问都串行化，严重降低了并发性；某些复合操作，仍然需要加锁来保护；迭代期间，若其它线程并发修改该容器，会抛出 ConcurrentModificationException 异常，即快速失败机制； Fork/Join 并行计算框架，这块内容是在 JDK1.7 中引入的，可以方便利用多核平台的计算能力，简化并行程序的编写，开发人员仅需关注如何划分任务和组合中间结果；框架的核心是 ForkJoinPool 类，实现了工作窃取算法（对那些处理完自身任务的线程，会从其它线程窃取任务执行）并且能够执行 ForkJoinTask 任务； TimeUnit 枚举，TimeUnit 是 java.util.concurrent 包下面的一个枚举类，TimeUnit 提供了可读性更好的线程暂停操作，以及方便的时间单位转换方法； 整个架构如下(下图转自这里!!!)： 参考 https://docs.oracle.com/javase/8/docs/api/index.html?java/util/concurrent/package-summary.html http://www.blogjava.net/xylz/archive/2010/06/30/324915.html https://www.zfl9.com/java-juc-framework.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存实现思路]]></title>
    <url>%2F2018%2F08%2F06%2FMyCache%2F</url>
    <content type="text"><![CDATA[缓存主要为了解决各个组件之间读取速度不匹配问题，比如寄存器是L1的缓存，L1是L2的缓存，L2是L3的缓存，L3是内存的缓存等。通过读Java Concurrency Practice P85，实现了一个简单可以添加和获取数据的缓存。其它的诸如缓存过期，更新缓存等没有实现- -!! 代码 计算接口，用到了装饰者模式。 1234public interface Computable&lt;A,V&gt; &#123; V compute(A arg);&#125; 一种计算的实现 1234567891011121314public class ExpensiveFunction implements Computable&lt;String,BigInteger&gt; &#123; @Override public BigInteger compute(String arg) &#123; // 经过长时间计算后 try &#123; Thread.sleep(500000); &#125; catch (InterruptedException ie) &#123; &#125; return new BigInteger(arg); &#125;&#125; 版本1 通过HashMap时间复杂度为O(1)的特性以及synchronized保证线程安全来构建缓存 123456789101112131415161718192021public class MyCacheV1&lt;A,V&gt; implements Computable&lt;A,V&gt;&#123; private Map&lt;A,V&gt; cache = new HashMap&lt;&gt;(); private Computable computable; public MyCacheV1(Computable computable) &#123; this.computable = computable; &#125; @Override public synchronized V compute(A arg) &#123; V result = cache.get(arg); if (result == null) &#123; result = (V)computable.compute(arg); cache.put(arg,result); &#125; return result; &#125;&#125; 版本2 版本1添加了synchronized，多线程情况下造成性能下降 -&gt; 换成ConcurrentHashMap 1234567891011121314151617181920public class MyCacheV2&lt;A,V&gt; implements Computable&lt;A,V&gt;&#123; private Map&lt;A,V&gt; cache = new ConcurrentHashMap&lt;&gt;(); private Computable computable; public MyCacheV2(Computable computable) &#123; this.computable = computable; &#125; @Override public V compute(A arg) &#123; V result = cache.get(arg); if (result == null) &#123; result = (V)computable.compute(arg); cache.put(arg,result); &#125; return result; &#125;&#125; 版本3 版本2先判断 -&gt; 在计算属于复合操作而且没有加锁导致线程不安全会产生重读计算。如果遇到计算时间非常长的计算，一旦重复会消耗大量的资源。解决思路：如果其他线程正在计算目标值，当前线程阻塞直到其它线程计算出结果返回即可。实现：通过FutureTask的get()方法。如果没有结果，会阻塞当前线程。 123456789101112131415161718192021222324252627282930313233343536public class MyCacheV3&lt;A,V&gt; implements Computable&lt;A,V&gt;&#123; private Map&lt;A,FutureTask&gt; cache = new ConcurrentHashMap&lt;&gt;(); private Computable computable; public MyCacheV3(Computable computable) &#123; this.computable = computable; &#125; @Override public V compute(A arg) &#123; Future future = cache.get(arg); if (future == null) &#123; FutureTask futureTask = new FutureTask(new Callable() &#123; @Override public V call() throws Exception &#123; return (V)computable.compute(arg); &#125; &#125;); // 用到了ConcurrentHashMap的原子操作 future = cache.putIfAbsent(arg,futureTask); // 二次判断 if (future == null) &#123;future = futureTask; futureTask.run();&#125; &#125; V result = null; try &#123; result = (V) future.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; return result; &#125;&#125;]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器框架源码阅读笔记（四）Map]]></title>
    <url>%2F2018%2F07%2F23%2FMap%2F</url>
    <content type="text"><![CDATA[java.util.Map框架： HashMap12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 预备知识 红黑树是一种特殊的二叉查找树，由平衡二叉查找树进化而来(在AVL中，保持全树的平衡开销太大)，红黑树只是保持局部平衡，即从每个节点向下直到叶子节点的路径中包含的黑色节点数量相同，达到一种”弱平衡”。它可以在 logn 时间内做查找，插入和删除，n是树中节点的数目。特性: 根节点是黑色 从任一节点到其每个叶子节点的所有简单路径都包含相同数目的黑色节点 叶子节点是不放数据的黑色节点 红色节点不能连续(红色节点的孩子和父亲节点颜色都不能是红色) 介绍 继承自AbstractMap，实现了Cloneable接口但是是浅拷贝，实现了Seriable可以进行序列化，实现了Map。 基于数组(Node) + 链表(Node) + 红黑树(TreeNode)实现，当链表长度达到8时，链表会变为红黑树。在resize()对红黑树进行切割split()时，如果切割后的红黑树大小减少到6就变回链表。 非线程安全，如果需要线程安全需要使用ConcurrentHashMap、Collections.synchronizedMap(new HashMap())、HashTable 可以存一个null key，数组下标默认是0，之后的null key会覆盖原来的。 数据不保证有序（放进去的顺序和拿出来的顺序不一样），如果需要有序可以使用TreeMap、LinkedHashMap 数组长度是2的幂,初始是16,最大值是32。 数组长度是2的幂,这样可以通过位操作(&amp;)代替%提高计算效率，数组.length – 1 使得低位数字全为1 使得 &amp; 数组.length – 1得到的分布比不是2的幂的情况要均匀。 通过用key的hashcode()再次求hash然后通过位运算得出要存的数组下标。 默认加载因子是0.75,当数组中元素的数量超过数组长度的0.75倍会进行扩容。 通过拉链法解决hash冲突，除此之外解决hash冲突的方法还有开放地址法(再散列法)、再哈希法、建立公共溢出区。 部分源码分析变量/常量1234567891011121314151617181920212223// 数组默认容量，2^4static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;// 数组最大容量 2^30static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认负载因子，如果没指定负载因子，就会用这个默认的。通过负载因子来确定阈值static final float DEFAULT_LOAD_FACTOR = 0.75f;// 链表树化阈值，当链表长度达到8就会变为红黑树static final int TREEIFY_THRESHOLD = 8;// 红黑树链化阈值，在resize()时，会对红黑树进行分割split(),如果分割后的红黑树元素个数减少到6就会变为链表static final int UNTREEIFY_THRESHOLD = 6;// 在变红黑树时，还会判断数组的【长度】是否大于64，如果小于64则直接进行扩容resize()，不会变为红黑树。static final int MIN_TREEIFY_CAPACITY = 64;// 求出的阈值，当键值对的数量大于该阈值后，就会进行resize()扩容int threshold;// 可以接收指定的负载因子final float loadFactor; get(Object key)12345678910111213141516171819202122232425262728293031323334353637383940/** * 根据key获取value * */ public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * 基本思路: * 根据提前计算好的hash =&gt; * 计算数组下标(hash &amp; (tab.length - 1)) =&gt; * 判断下标元素是否是查找的节点 =&gt; * 是：直接返回节点 * 不是:继续在红黑树 || 单链表中查找 * */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 预判断:数组是否为null，数组长度是否为0，求出的下标对应的元素是否为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 求出的下标对应的数组元素就是要获取的目标节点(如果两个key相同，那么hash肯定相同，所在先比较的hash。再就是先判断两个key是否指向同一个对象，如果指向同一个对象，就不用再执行耗时的equals操作) if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 求出的下标对应的数组元素不是要获取的节点 if ((e = first.next) != null) &#123; // 从红黑树中查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 从单链表中查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; put(K key, V value)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * 将key，value插入到HashMap中 * */public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;/** * 基本思路: * 根据提前计算的hash =&gt; * 计算要插入的数组下标(hash &amp; (tab.length - 1)) =&gt; * 根据是链表还是红黑树插入目标节点 * */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 指向当前数组 Node&lt;K,V&gt;[] tab; // 指向数组下标为 "hash与数组长度取模后((n - 1) &amp; hash)" 的元素 Node&lt;K,V&gt; p; // n是数组长度，i是元素要插入的下标((n - 1) &amp; hash) int n, i; // 如果数组为null，代表数组还没有初始化。需要执行resize()初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果求出的数组下标对应的元素为null，代表该下标还没有元素，则直接在该下标添加元素 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 如果求出的数组下标已经存在元素，判断是红黑树还是链表 else &#123; // 找到HashMap中该key对应的元素，然后让e指向该元素。当然也可能不存在该key对应的元素，从而找不到，使得e为null。 // 后续通过判断e是否为null来决定此次put是更新操作还是插入操作。 // 如果e为null，说明HashMap中并不存在key对应的元素，直接执行的插入操作 // 如果e不为null，说明HashMap中存在该key对应的元素，并且让e指向了该元素，需要执行更新操作，更新key对应元素的value。 Node&lt;K,V&gt; e; K k; // 如果是求出的数组下标的元素key和hash与新传进来的key和hash相同(传过来的key已经存在于数组中) if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 注意此时并没有更新节点值，只是将e指向该节点(此时e不为null)，最后会判断e是否为null，决定是否更新。 e = p; // 如果数组元素类型是红黑树 =&gt; 将新节点插入/更新到红黑树中 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 数组元素是单链表，进行尾插 for (int binCount = 0; ; ++binCount) &#123; // 插入到表尾 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 插入元素后，如果当前链表长度 &gt; 7 则调用treefyBin() "决定是否" 变红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 因为binCount 从0开始，当binCount等于7时，代表链表长度为8。 // 将链表改为红黑树 treeifyBin(tab, hash); break; &#125; // 尾插过程中，如果已经存在此key，将e指向此key，退出。后面进行更新旧值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果是已经存在的key，上面的遍历过程只是找到key对应的节点，并没有更新值 // 最后需要更新节点旧值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; // 记录修改次数，fail-fast机制要用到 ++modCount; // 如果元素(键值对)数量大于阈值，则进行扩容 if (++size &gt; threshold) resize(); // LinkedHashMap通过重写它，执行后续的操作：将这个节点添加到双向链表尾部。 afterNodeInsertion(evict); return null;&#125;/** * 还会进一步判断数组长度是否小于MIN_TREEIFY_CAPACITY，来决定是否变红黑树 * */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; // 如果数组长度比较小就直接扩容（小于变红黑树的阈值），不用变成红黑树。 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); // 将该位置对应的链表变为红黑树 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; public V remove(Object key)删除key对应的节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; // 指向原数组 Node&lt;K,V&gt;[] tab; // 指向求出的数组下标对应的元素 Node&lt;K,V&gt; p; // n为数组长度，index为通过key求出的下标 int n, index; // 判断边界条件：数组是否为null、数组长度是否为0、下标对应的元素是否为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; // node最终指向要删除的节点 Node&lt;K,V&gt; node = null, e; K k; V v; // 判断下标对应的元素是否就是要删除的元素，如果是，直接将node指向这个元素 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; // 如果不是的话，要删除的元素可能在红黑树里或者在单链表中 else if ((e = p.next) != null) &#123; // 如果在数组下标元素类型是红黑树节点类型就在红黑树中查找欲删除的节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); // 如果数组下标元素类型是单链表节点类型就在链表中查找欲删除的节点 else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 删除node指向的节点(因为执行了上面的代码，如果欲删除的元素在map中，此时node已经指向欲删除的元素) if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // 如果要删除的节点类型是红黑树，就执行红黑树删除节点的api if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); // 如果要删除的节点类型是单链表，就执行单链表删除节点操作，下面的p此时是node的前置节点(因为在遍历单链表时，p一直在node前面) else if (node == p) tab[index] = node.next; else p.next = node.next; // 添加修改次数 ++modCount; // 键值对数量减1 --size; // 执行完删除节点操作以后，会执行LinkedHashMap重写的这个方法(实际上就是执行双向链表的删除节点的操作，因为LinkedHashMap里的是双向链表) afterNodeRemoval(node); // 返回删除的节点 return node; &#125; &#125; return null;&#125; resize()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * 2倍扩容数组长度 * */ final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 如果当前数组存在元素：不是新创建的 if (oldCap &gt; 0) &#123; // 如果当前数组长度大于等于允许的最大容量 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 阈值就变成无穷大 threshold = Integer.MAX_VALUE; return oldTab; &#125; // 如果当前数组长度没有超过最大长度，二倍扩容数组长度和阈值 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 通过HashMap(int initialCapacity, float loadFactor) 或者 HashMap(int initialCapacity) 【新】创建的HashMap对象 // 新创建的HashMap对象的阈值threshold的值是通过初始长度initialCapacity生成的一个2的幂。 // 然后将阈值赋给newCap的目的是保证最终创建的数组长度是2的幂。 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 新创建的：直接调用的无参构造函数 // 数组长度和加载因子/阈值直接使用默认生成的。 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 针对 " else if (oldThr &gt; 0) " 求阈值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; // 判断要设置数组长度是否超过了允许的最大容量，来决定阈值的值是现在的值((float)newCap * loadFactor)还是Integer.MAX_VALUE newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 设置阈值 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) // 生成一个二倍长度的新数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 如果是旧数组 =&gt; 直接拷贝元素到新数组 // 元素在旧数组 if (oldTab != null) &#123; // 遍历旧数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 如果只有一个元素（只有一个单链表的头节点或者只有一个红黑树的根节点） if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果不只一个元素，并且元素类型是TreeNode else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 如果不只一个元素，并且是单链表 =&gt; 遍历单链表 // 保留整个单链表的顺序，然后整体移动到newTab[X ，X如下↓]后面 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 运算结果为0的元素，用loHead记录并连接成新的链表 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 运算结果不为0的元素，用hiHead记录并连接成新的链表 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 参考Q&amp;A if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; Q&amp;A JDK8在resize()中，将原先的链表通过if((e.hash &amp; oldCap) == 0)分割成两个子链表，这两个子链表在新数组中的下标为什么是j和j + oldCap？这样在新数组中通过hash &amp; newTab.length - 1能对应上？ 对于(e.hash &amp; oldCap) == 0的元素(后面的分析都是基于这个前提) =&gt; 在原数组中的下标等于要转移到新数组中的下标。原因： (e.hash &amp; oldCap) == 0?就是判断oldCap高位对应的hash位是否为0。未扩容之前,hash只和oldCap - 1低位做&amp;运算来求在原始数组中的下标,扩容之后本质上还是和oldCap - 1低位做&amp;运算来求在新数组中的下标。 二倍扩容后，新数组的长度newCap为oldCap &lt;&lt; 1，之后求元素在新数组中的下标(hash &amp; (newCap - 1))。因为 newCap - 1高位为0,与此同时高位后一个位(也就是oldCap高位)对应的hash位也为0,所以(hash &amp; (newCap - 1))等价于(hash &amp; (oldCap - 1))。举个例子： 假设oldCap值是2^4 = 16,某个元素e的hash是0111 0101。这个元素在原始数组中的下标应该是hash &amp; oldCap - 1 = 5。此时(e.hash &amp; oldCap) == 0,根据结论：如果扩容以后，元素e所在新数组的下标应该还是hash &amp; oldCap - 1 = 5。 事实是这样：hash &amp; newCap - 1 = 5。 变量 二进制值 备注 oldCap 0000 1000 因为是2的幂所以高位为1,低位全为0。 hash 0111 0101 随意选的 oldCap - 1 0000 0111 oldCap - 1的高位为0,低位全为1 newCap 0001 0000 等于2*oldCap，将oldCap左移一位即可 此时hash &amp; oldCap = 0推出oldCap高位对应的hash位一定为0。否则求出的值绝对不是0。如下图：当通过hash &amp; (newCap - 1)求元素e在新数组中的下标，实际是和最后三位进行&amp;运算，计算结果和hash &amp; (oldCap - 1)一样 变量 二进制值 备注 hash 0111 0101 oldCap高位对应的hash位为0 newCap -1 0000 1111 oldCap - 1 0000 0111 对于(e.hash &amp; oldCap) != 0的元素(后面的分析都是基于这个前提) =&gt; 扩容后元素e在新数组中的下标等于元素e在原数组中的下标+原数组长度。 原因：（新数组下标计算过程） 新数组下标 hash &amp; (newCap - 1)👇 hash &amp; (2 * oldCap - 1)👇 hash &amp; (oldCap + oldCap -1)👇 (hash &amp; oldCap - hash &amp; 1) + hash &amp; oldCap👇 由(e.hash &amp; oldCap) != 0可以推出oldCap高位对应的hash位不为0可以推出hash &amp; oldCap == oldCap hash &amp; (oldCap - 1) + oldCap👇 原数组下标 + 原数组长度数组 变量 二进制值 备注 hash 0111 1101 oldCap高位对应的hash位不为0 newCap -1 0000 1111 oldCap - 1 0000 0111 为什么长度为6时用链表，为8时用红黑树？中间的7是干嘛的？ 因为红黑树查找时间复杂度为O(LogN)，链表查找时间复杂度为O(N)，当链表中节点数量较多时，为了提高查找效率会采用红黑树。又因为红黑树的节点大约是链表节点的两倍，所以为了节省空间，链表转红黑树的阈值不能太小。 对于分布均匀的hash函数来说，桶中冲突元素的数量服从泊松分布，冲突元素数量是8的概率为千万分之一，是一个小概率事件，如果这个小概率事件发生了，说明冲突比较严重，这时就会将链表转为红黑树提高查询效率。 Because TreeNodes are about twice the size of regular nodes, we use them only when bins contain enough nodes to warrant use (see TREEIFY_THRESHOLD). And when they become too small (due to removal or resizing) they are converted back to plain bins. 中间隔一个7为了防止链表和红黑树频繁转换影响效率。如果不隔7的话，元素个数频繁从6变到7或者从8变到7，会造成红黑树和链表频繁的进行转换。(个人理解) 为什么不是线程安全的?具体体现在哪儿? 在多线程的情况下，并发执行resize()可能会产生环形链表，从而在get()时可能差生inflate loop。 比如并发插入元素时，会并发修改size。 为什么产生环形链表？ 主要是由于转移链表时在新数组中的顺序和原数组顺序不一致导致的。 疫苗：JAVA HASHMAP的死循环 A Beautiful Race Condition(需要科学上网) 为什么求出hashCode()之后要二次hash？ 二次hash为了使得哈希码低位元素更加具有随机性。 为什么数组长度是2的幂？ 可以通过位操作&amp;代替%进行取模运算提高效率。 可以使得求出的数组下标充分依赖hash码，因为2的幂 - 1保证了低位全为1，做&amp;运算可以完全依赖hash，而hash已经通过二次hash随机性很强，从而使得分布会相对均匀。 为什么加载因子loadFactor默认是0.75？ 加载因子太大：空间利用率高，查询效率变低，容易发生冲突。 加载因子太小：不容易产生冲突，查询效率高，空间利用率低，频繁扩容会产生性能影响 As a general rule, the default load factor (.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the HashMap class, including get and put). The expected number of entries inthe map and its load factor should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum number of entries divided by the load factor, no rehash operations will ever occur. JDK8和JDK7关于HashMap的区别? JDK7基于数组加链表实现，JDK8引入了红黑树解决了发生hash冲突后，链表过长导致查询效率变低的问题。 JDK7采用单链表头插法解决hash冲突，JDK8采用尾插法 JDK8 resize()后的链表中元素的相对顺序不变。不会产生环形链表（个人看法，没证明） JDK7数组类型是Entry类型，JDK8改为Node类型都是实现的Map.Entry接口。只是改了个名字 HashMap和HashTable的区别？ HashMap相对于HashTable可以存nul key 和 null value。 HashTable相对于HashMap是线程安全的。 The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls. 为什么key一般用不变对象，比如String、Integer？ 如果对象可变，比如User对象的name属性变了则计算出来的hash会变化，导致求出的数组下标会变从而找不到之前User对应的value。建议key尽量是String或者Integer，不应该是可变的对象。 解决hash冲突的方法？ 开放地址法(再散列法) 线性探测：如果冲突了以后，继续向后查找直到找到一个空位 二次探测：相对于线性探测，它是两步两步的跳着找空位，比较灵活 开放地址法适合存放较少数量的键值对，比如Thread中维护的ThreadLocalMap就是用的开放地址法解决的哈希冲突，因为一般通过ThreadLocal设置的键值对数量比较少。如果存放的数量过多，最坏的时间复杂度可能会达到O(n) 链地址法：将冲突的元素，构造成一个单链表 再哈希法：提前构造多个hash函数，如果某个hash函数冲突以后，再换别的hash函数，直到找到不冲突的为止 建立公共溢出区：将冲突的元素放到溢出区中，和不冲突的元素分开。 参考 Java：手把手带你源码分析 HashMap 1.7 Java HashMap.get(Object) infinite loop Java 容器源码分析之 HashMap LinkedHashMap1public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; 介绍 LinkedHashMap继承自HashMap，在此基础上，将所有键值对用双向链表链了起来，这样可以实现元素的迭代顺序和元素的插入顺序一致。在HashMap基础上加了钩子函数，可以实现元素的迭代顺序和元素的访问顺序一致(访问一个元素以后就会将元素放到双链表的尾部)，通过这个特性可以实现LRU cache LinkedHashMap不是线程安全的，如果需要线程安全需要使用Collections.synchronizedMap(new LinkedHashMap()) LinkedHashMap继承了HashMap，用到了模板模式。一般的get、put、remove、都用到了HashMap中的操作 部分源码解析变量1234567891011121314151617181920// 双向链表头指针，在LRU中可以理解为最【老】的节点(如果缓存不够最先剔除的节点)/** * The head (eldest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; head;// 双向链表尾指针，在LRU中可以理解为最【新】的节点(如果缓存不够最先剔除的节点)/** * The tail (youngest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; tail;// 如果是true遍历时按访问顺序，false遍历时按插入顺序。/** * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * * @serial */final boolean accessOrder; void afterNodeInsertion(boolean evict)插入元素e后会根据removeEldestEntry(first)这个方法设定的阈值来决定是否要移除最老的元素 12345678910111213// 当向map中插入元素后执行的操作void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; // 执行HashMap中的删除节点api。 first=head就是最老的节点。(看###变量注释👆) removeNode(hash(key), key, null, false, true); &#125;&#125;// 默认直接返回true，可以定制 return size() &gt; 123; 当键值对的数量大于123时就会删除最老的元素。方便实现LRU cacheprotected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; public V get(Object key)访问元素e后，如果提前设置了accessOrder为true，就会调用afterNodeAccess(Node&lt;K,V&gt; e)将元素e放到链表的末尾(tail),来实现LRU Cache。 123456789101112131415161718192021222324252627282930313233343536373839public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value;&#125;void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last // 指向每一个 LinkedHashMap.Entry&lt;K,V&gt; last; // 如果设置的访问顺序，也就是accessOrder为true并且链表最后一个节点不是e。就将刚才访问的e这个节点放到最后面 if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; // 将节点e的前后节点拼接起来，然后移除e，将e放到链表尾部。 if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; // 链表尾指针为空(这是放的第一个元素)，就让head指针指向节点e if (last == null) head = p; // 将这个节点放到链表的尾部 else &#123; p.before = last; last.after = p; &#125; // 将双向链表尾指针指向e(将e放到双向链表最后面) tail = p; // 修改次数+1 ++modCount; &#125;&#125; afterNodeRemoval(Node&lt;K,V&gt; e)当执行HashMap中的remove(Object key)删除节点key对应的元素e后，会执行双向链表中删除节点的操作 12345678910111213141516void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; // p是头节点 if (b == null) head = a; // p不是头节点 else b.after = a; // p是尾节点 if (a == null) tail = b; // p不是尾节点 else a.before = b;&#125; Q&amp;A 实现一个LRU Cache？ 设置accessOrder为true，保证最近访问过的元素是最新元素 重写removeEldestEntry(Map.Entry eldest)设置一个缓存大小 1234567891011121314151617181920212223242526public class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; public static final int CACHE_SIZE = 3; protected boolean removeEldestEntry(Map.Entry eldest) &#123; return size() &gt; CACHE_SIZE; &#125; public LRUCache() &#123; super(CACHE_SIZE,0.75f,true); &#125; public static void main(String[] args) &#123; LRUCache&lt;Integer, String&gt; lru = new LRUCache(); lru.put(1,"a"); lru.put(2,"b"); lru.put(3,"c"); // 因为是从双向链表头部开始遍历到尾部，结果应该是 [1,2,3]， System.out.println(lru.keySet()); lru.get(2); // 因为访问了2，所以会将2放到尾部，从双向链表头开始遍历到尾部，结果应该是[1,3,2] System.out.println(lru.keySet()); lru.put(4,"d"); // 因为缓存容量设置的是3，所以添加4时 由于缓存已经满了，所以需要删除最老的，就是双向链表头部 1，最后结果应该是[3,2,4] System.out.println(lru.keySet()); &#125;&#125; WeakHashMap1public class WeakHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; 预备知识Java中的四种引用不同的引用类型体现了对垃圾回收的影响，并且可以在一定程度上允许我们干涉自动垃圾回收器。在Java中主要有四种引用类型： 强引用(StrongReference)强引用是通过赋值运算符=将所引用的对象obj关联起来。比如Object obj = new Object()。如果一个对象的强引用还在，该对象就不会被JVM回收。 软引用(SoftReference)软引用通过SoftReference将所引用的对象obj👆关联起来。比如SoftReference sr = new SoftReference(obj)。在内存不足要发生内存溢出OOM之前，会被JVM回收。 如果SoftReference注册了引用队列ReferenceQueue，当回收软引用关联的对象之后，会将该软引用加入到ReferenceQueue。 和软引用关联的对象有用但不是必需的，所以软引用可以做缓存。当JVM内存不足时，会将这部分缓存回收掉。比如用户打开了多个图片，就需要加载多个图片内容到内存中，每个图片内容(字节数组)可以和软引用关联当作缓存，如果内存不足时就会清除内存中缓存的图片内容(字节数组)。不过要注意:当要再次查看图片时每次都要判断图片内容是否已经被回收(判断引用队列中是否有引用了)，如果被回收需要重新加载到内存。 123456789101112131415161718192021222324252627282930313233343536373839// 一个Image相当于一个图片，如果打开多个图片等价于创建多个Image对象public class Image &#123; // 图片路径 private String path; // 通过字节数组存放图片内容 private byte[] data; // 要和Image对象关联的软引用 private SoftReference&lt;byte[]&gt; softReference; // 构造图片 Image(String path) &#123; this.path = path; // 将图片加载进来 data = readImageByPath(path); softReference = new SoftReference&lt;&gt;(data); &#125; private byte[] readImageByPath(String path) &#123; // 为了方便，没有具体实现,一次1MB_ return new byte[1024 * 1024]; &#125; public byte[] getData() &#123; byte[] dataArray = softReference.get(); // 判断data是否已经被回收了，如果被回收了需要重新读取图片内容到内存中 if (dataArray == null || dataArray.length == 0) &#123; dataArray = readImageByPath(path); softReference = new SoftReference&lt;&gt;(dataArray); &#125; return dataArray; &#125; public static void main(String[] args) &#123; // 同时打开100张图片 for (int i = 100; i &gt; 0; i++) &#123; Image image = new Image(i + ".jpg"); &#125; &#125;&#125; 弱引用(WeakReference) 弱引用通过WeakReference将所引用的对象obj关联起来。比如WeakReference sr = new WeakReference(obj),和弱引用关联的对象在垃圾回收时，会被JVM回收。 如果WeakReference注册了引用队列ReferenceQueue，当回收弱引用关联的对象之后，会将该弱引用加入到ReferenceQueue。 和弱引用关联的对象不是必需的，弱引用多用在哈希表中，比如WeakHashMap通过WeakReference可以回收每一个被回收的key对象所关联的Entry(详细见下面源码分析👇) 软引用、弱引用基本上没有本质上的区别，仅仅是软引用对象比弱引用对象的命更长一些罢了。(参考链接)因此，软引用、弱引用都适合用来实现内存敏感的高速缓存，具体使用哪种引用，这里给几条参考：1) 如果只是想避免 OutOfMemory 的发生，则可以使用软引用；如果对于性能更在意，想尽快回收一些占用内存比较大的对象，则可以使用弱引用。2) 如果对象可能会经常使用的，就尽量用软引用；如果对象不被使用的可能性更大些，就可以用弱引用。 幽灵引用(PhantomReference) 幽灵引用通过PhantomReference将所引用的对象obj关联起来。比如PhantomReference sr = new PhantomReference(obj)，和幽灵引用关联的对象等价于没有被引用，随时可能被回收。所以如果不给幽灵引用注册引用队列，那这个幽灵引用就没有意义。 如果PhantomReference注册了引用队列ReferenceQueue，当回收幽灵引用关联的对象之前(finalize()之后)，会将该幽灵引用放到引用队列中。 因为每个对象在回收之前，还会执行继承自Object的finalize()用来做一些资源清理的操作，但是JVM什么时间执行finalize()不是确定的。考虑一个场景，在要分配内存创建新的对象时，要确定某个对象要被回收才能分配。此时可以通过幽灵引用结合引用队列实现，当执行了finalize()会将要回收的对象关联的幽灵引用放到引用队列中。此时可以确定这个对象马上要被回收，可以分配内存。 12345678910111213141516171819202122public class PhantomBuffer &#123; private byte[] data = new byte[0]; private ReferenceQueue&lt;byte[]&gt; queue = new ReferenceQueue&lt;byte[]&gt;(); private PhantomReference&lt;byte[]&gt; ref = new PhantomReference&lt;byte[]&gt;(data, queue); public byte[] get() &#123; // 会阻塞直到队列 非空。非空以后说明已经执行了要被回收的对象的finalize()，可以分配新的内存 queue.remove(); // 幽灵引用不会自动清空，要手动运行 ref.clear(); ref = null; // 分配内存 data = new byte[111]; // 重新关联 ref = new PhantomReference&lt;byte[]&gt;(data, queue); return data; &#125;&#125; 介绍WeakHashMap中的Entry内部的key指向的对象可能会被GC回收，即使没有手动调用remove()或者clear()方法。因为WeakHashMap中的Entry继承自WeakReference，把key引用的对象和弱引用关联起来(Entry继承了WeakReference，也就是将key和Entry关联起来)在JVM进行垃圾回收时会将key引用的对象回收。每次执行get、put、resize()等操作时会根据引用队列提前判断key所引用的对象是否被回收来决定是否清除该key关联的Entry以及Entry中的value指向的对象,来尽量避免内存泄漏。 部分源码分析Entry结构Entry继承了WeakReference，此时Entry也是一个虚引用。每次创建新的Entry时会将key和Entry关联，并且中。当回收了key所引用的对象以后,会将Entry放到引用队列queue中。所以在每次操作时都会从引用队列中取一个Entry释放掉。 12345678910111213141516171819private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; &#123; V value; final int hash; Entry&lt;K,V&gt; next; /** * Creates new entry. */ Entry(Object key, V value, ReferenceQueue&lt;Object&gt; queue, int hash, Entry&lt;K,V&gt; next) &#123; // 将key和Entry关联，并且给Entry注册一个引用队列queue super(key, queue); this.value = value; this.hash = hash; this.next = next; &#125; // 后续没写&#125; public V get(Object key)根据key获取value，当调用gettable()时会调用expungeStaleEntries()，然后从引用队列中取出Entry,释放掉Entry以及Entry中的value。在WeakHashMap定义的增、删、改、查方法中，都要调用gettable()。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V get(Object key) &#123; // 如果传入的key是null就用Object代替 Object k = maskNull(key); // 求hash值确定下标 int h = hash(k); // 获取原始数组，并且执行getTable()还会调用expungeStaleEntries() Entry&lt;K,V&gt;[] tab = getTable(); // 获取下标 int index = indexFor(h, tab.length); // 找value Entry&lt;K,V&gt; e = tab[index]; while (e != null) &#123; // e.get()返回和Entry关联的key if (e.hash == h &amp;&amp; eq(k, e.get())) return e.value; e = e.next; &#125; return null;&#125;private Entry&lt;K,V&gt;[] getTable() &#123; expungeStaleEntries(); return table;&#125;// 从引用队列中取出Entry释放掉Entry以及Entry中的valueprivate void expungeStaleEntries() &#123; // 从引用队列中取出Entry for (Object x; (x = queue.poll()) != null; ) &#123; synchronized (queue) &#123; @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x; int i = indexFor(e.hash, table.length); // 释放Entry(类似删除单链表节点)以及Entry中的value(将e.value=null) Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; p = prev; while (p != null) &#123; Entry&lt;K,V&gt; next = p.next; if (p == e) &#123; if (prev == e) table[i] = next; else prev.next = next; // Must not null out e.next; // stale entries may be in use by a HashIterator // 释放Entry中的value e.value = null; // Help GC // 键值对数量减1 size--; break; &#125; prev = p; p = next; &#125; &#125; &#125;&#125; 参考 Java 深度历险（四）——Java 垃圾回收机制与引用类型 Java 4种引用类型 WeakHashMap Java集合框架源码解读(4)——WeakHashMap TreeMap1public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, Serializable 介绍 TreeMap是基于红黑树实现的一种Map，对于get、put、remove时间复杂度是log(n)。元素是有序的，顺序是按照key的自然顺序或者是定义的Comparator。 TreeMap不是线程安全的。如果需要线程安全的TreeMap需要使用SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...)); TreeMap实现了NavigableMap间接实现了SortedMap。注意的是SortedMap比较两个key是否相等不是按Map中规定的equals()，而是用自己定义的Comparator中的compareTo()。 参考Java doc： This is so because the Map interface is defined in terms of the equals operation, but a sorted map performs all key comparisons using its compareTo (or compare) method, so two keys that are deemed equal by this method are, from the standpoint of the sorted map, equal. The behavior of a sorted map is well-defined even if its ordering is inconsistent with equals; it just fails to obey the general contract of the Map interface. 使用注意因为是通过compareTo()比较两个key是否相等，如果compareTo()写错了会出现TreeMap中明明存在该key，并且equals()返回true，但是get()返回null。如下：(下面代码转自廖雪峰大神) 12345678910111213141516171819202122232425262728public class Student implements Comparable&lt;Student&gt; &#123; final String name; final int score; public Student(String name, int score) &#123; this.name = name; this.score = score; &#125; @Override public int hashCode() &#123; return Objects.hash(name, score); &#125; @Override public boolean equals(Object obj) &#123; if (obj instanceof Student) &#123; Student o = (Student) obj; return Objects.equals(this.name, o.name) &amp;&amp; this.score == o.score; &#125; return false; &#125; @Override public int compareTo(Student o) &#123; return this.score &lt; o.score ? -1 : 1; &#125;&#125; 用HashMap测试能正常输出 99 88 77。 1234567Map&lt;Student, Integer&gt; map = new HashMap&lt;&gt;();map.put(new Student("Michael", 99), 99);map.put(new Student("Bob", 88), 88);map.put(new Student("Alice", 77), 77);System.out.println(map.get(new Student("Michael", 99)));System.out.println(map.get(new Student("Bob", 88)));System.out.println(map.get(new Student("Alice", 77))); 用TreeMap测试输出 null null null，因为通过hash确定下标后，通过compareTo()返回值是否为0找到key，但是现在compareTo()不会返回0…..，所以会找不到key，然后返回null。重写compareTo()，保证当key相等时返回0 12345public int compareTo(Student o) &#123; int result = Integers.compare(this.score,o.score); return result != 0 ? result : this.name.compareTo(o.name); //return this.score &lt; o.score ? -1 : 1;&#125; 应用场景一致性哈希 代码实现思路参照链接实现负载均衡，因为TreeMap提供了获取第一个大于当前节点的API，ceilingEntry() 建环 构造虚拟节点 接受请求，根据请求定位12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class ConsitentHash &#123; // 虚拟节点数量 private static final int VIRTUAL_NODE_SIZE = 1000; // 每个物理服务器中虚拟节点的分隔符 private static final String DILEMMA = "-"; // 哈希策略 private HashStrategy hashStrategy = new JDKHashCodeStrategy(); public Server select(List&lt;Server&gt; servers, Request request) &#123; TreeMap&lt;Integer, Server&gt; hashRing = buildRing(servers); return locate(request, hashRing); &#125; private TreeMap&lt;Integer, Server&gt; buildRing(List&lt;Server&gt; servers) &#123; TreeMap&lt;Integer, Server&gt; hashRing = new TreeMap&lt;&gt;(); servers.forEach(server -&gt; &#123; for (int i = 0; i &lt; VIRTUAL_NODE_SIZE; i++) hashRing.put(hashStrategy.getHashCode(server.getUrl() + DILEMMA + i), server); &#125;); return hashRing; &#125; private Server locate(Request request, TreeMap&lt;Integer, Server&gt; hashRing) &#123; Server server; int key = hashStrategy.getHashCode(request.getHashKey()); Map.Entry&lt;Integer, Server&gt; serverEntry = hashRing.ceilingEntry(key); return serverEntry == null ? hashRing.firstEntry().getValue() : serverEntry.getValue(); &#125; class Server &#123; private String url; public void setUrl(String url) &#123; this.url = url; &#125; public String getUrl() &#123; return this.url; &#125; &#125; abstract class HashStrategy &#123; public abstract int getHashCode(String origin); &#125; class JDKHashCodeStrategy extends HashStrategy &#123; @Override public int getHashCode(String origin) &#123; return origin.hashCode(); &#125; &#125; class Request &#123; private String hashKey; public String getHashKey() &#123; return hashKey; &#125; public void setHashKey(String hashKey) &#123; this.hashKey = hashKey; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器框架源码阅读笔记（三）Set]]></title>
    <url>%2F2018%2F07%2F22%2FSet%2F</url>
    <content type="text"><![CDATA[java.util.Set框架： SetSet对Map进行了包裹,利用Map中key的唯一性保证集合中元素的唯一性，所有的key指向同一个对象。 HashSet直接用的HashMap，元素的顺序是不确定的，查找删除等操作的时间复杂度为O(1)。 12345678910111213// 所有key指向这个对象// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object();public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;// 返回值是boolean，可以判断是否插入成功，也就是说是否已经存在相应的元素epublic boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; LinkedHashSet直接用的LinkedHashMap,元素的顺序是确定的，查找删除等操作的时间复杂度为O(1)。 123456public LinkedHashSet() &#123; super(16, .75f, true);&#125;HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; TreeSet直接用的TreeMap，元素是有序的，查找删除等操作的时间复杂度为O(logn)。元素是有序的，顺序是按照key的自然顺序或者是定义的Comparator。 构建线程安全的TreeSet：SortedSet s = Collections.synchronizedSortedSet(new TreeSet(...)); 123public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;());&#125; 参考 TreeSet and TreeMap CYC2018 Java容器]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器框架源码阅读笔记（二）Queue、Stack]]></title>
    <url>%2F2018%2F07%2F21%2FQueue%26%26Stack%2F</url>
    <content type="text"><![CDATA[java.util.Queue和java.util.Stack框架： Queue1public interface Queue&lt;E&gt; extends Collection&lt;E&gt; 介绍 Queue是一个队列接口，继承自Collection。定义了关于FIFO队列的相关操作。 Queue的子接口Deque扩展了Queue。Deque除了继承了FIFO队列的相关操作，Deque还定义了关于双端队列、栈的相关操作。 LinkedList、ArrayDeque通过实现Deque间接实现了Queue。 在 Queue中定义了三类方法，关于每类方法(增删查)都定义了两种，区别在于出现错误后(比如删除元素/获取队头元素队列已经空了)是抛异常还是返回错误值。对于返回错误值的方法应用场景是队列长度有限制的实现类。 Each of these methods exists in two forms: one throws an exception if the operation fails, the other returns a special value (either null or false, depending on the operation). The latter form of the insert operation is designed specificallyfor use with capacity-restricted Queue implementations; in most implementations, insert operations cannot fail. operation Throws exception Returns special value Insert add(e) offer(e) Remove remove() poll() Examine element() peek() 队列操作部分源码分析主要翻译ArrayDeque中关于队列操作的具体实现。ArrayDeque是通过数组实现了一个循环队列。队列长度可变，当数组元素满了以后，就进行2倍扩容。变量head、tail分别表示队头和队尾。head指向队头的元素位置，tail指向队尾元素的下一个位置，也就是下一个要插入的元素应该在的位置。 public boolean add(E e)添加元素到队尾，通过(tail + 1) &amp; (elements.length - 1)) == head判断队列是否已满(因为队列的长度是2的幂，所以可以通过位运算&amp;来代替%) 12345678910111213141516public boolean add(E e) &#123; addLast(e); return true;&#125;public void addLast(E e) &#123; // 不允许添加null if (e == null) throw new NullPointerException(); // 将元素插入到队尾元素的后面 elements[tail] = e; // 判断队列是否已经满了，将队列长度设置为2的幂，可以用位运算代替取模运算 if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head) // 满了以后进行2倍扩容，所以判断队列满和队列空 用head == tail不冲突，因为队列不会满，一旦由于添加元素导致head == tail时，就会进行二倍扩容，保证tail不会因为添加元素【最终】指向head doubleCapacity();&#125; public E element()获取队头元素，没有通过head == tail判断队列是否为空，而是通过取得head指针指向的元素是否为空来判断队列是否为空。 如果队列为空，element()会抛异常。对应的peek()会返回null。 12345678910111213public E element() &#123; return getFirst();&#125;public E getFirst() &#123; @SuppressWarnings("unchecked") // 获取头指针head指向的队头元素 E result = (E) elements[head]; // 如果获取的元素是null，直接抛出异常。 if (result == null) throw new NoSuchElementException(); return result;&#125; public E remove()删除队头元素，没有通过head == tail判断队列是否为空，而是通过取得head指针指向的元素是否为空来判断队列是否为空。 如果队列为空，remove()会抛异常。对应的poll()会返回null。 1234567891011121314151617181920212223242526public E remove() &#123; return removeFirst();&#125;public E removeFirst() &#123; E x = pollFirst(); if (x == null) throw new NoSuchElementException(); return x;&#125;public E pollFirst() &#123; // 获取head指针 int h = head; @SuppressWarnings("unchecked") // 获取队头元素 E result = (E) elements[h]; // Element is null if deque empty if (result == null) return null; // 将队头变量置空(删除) elements[h] = null; // Must null out slot // 修改head指针 head = (h + 1) &amp; (elements.length - 1); return result;&#125; Stack1public class Stack&lt;E&gt; extends Vector&lt;E&gt; 介绍Stack继承自Vector，是一个LIFO的线性数据结构，只能在栈顶进行操作。通过Vector实现了关于栈的基本操作，当需要使用栈时，Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque。 A more complete and consistent set of LIFO stack operations is provided by the Deque interface and its implementations, which should be used in preference to this class. For example:Deque&lt;Integer&gt; stack = new ArrayDeque&lt;Integer&gt;(); 个人观点: 原生的Stack是继承是Vector，而Vevtor中的每个方法是加了锁的，所以在效率上可能会降低。不过在JDK6已经对synchronized做了优化，没对比过。 栈和队列都是在一端或两端操作，不会直接对中间元素操作(删除，添加)，所以可以避免数组操作中间元素产生较大的时间开销，再就是数组占用的内存在物理上是连续的，所以能更好的用到局部性原理吧。 栈操作部分源码分析主要翻译ArrayDeque中关于栈操作的具体实现。 public void push(E e)入栈 12345678910111213public void push(E e) &#123; addFirst(e);&#125;public void addFirst(E e) &#123; if (e == null) throw new NullPointerException(); // 放在head指向的元素之前，然后栈顶指针往 "前" 循环走 elements[head = (head - 1) &amp; (elements.length - 1)] = e; // 当head和tail相遇，说明栈满，需要扩容。 if (head == tail) doubleCapacity();&#125; public E pop()出栈 1234567891011121314151617181920212223public E pop() &#123; return removeFirst();&#125;public E removeFirst() &#123; E x = pollFirst(); if (x == null) throw new NoSuchElementException(); return x;&#125;public E pollFirst() &#123; int h = head; @SuppressWarnings("unchecked") E result = (E) elements[h]; // 如果栈是空的，最终获取的元素就是null if (result == null) return null; elements[h] = null; // Must null out slot // 栈顶指针往 "后" 循环走 head = (h + 1) &amp; (elements.length - 1); return result;&#125; Q&amp;AFIFO队列和栈的区别？ 队列是一个先进先出(First In First Out)的线性数据结构。可以在队头和队尾进行操作。 栈是一个后进先出(First In Last Out)的线性数据结构。只能在栈顶进行操作。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器框架源码阅读笔记（一）List]]></title>
    <url>%2F2018%2F07%2F20%2FList%2F</url>
    <content type="text"><![CDATA[java.uti.List框架： ArrayList12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 介绍 继承自AbstractList。实现了List。实现了RandomAccess标记接口表示可以随机访问。实现了Cloneable标记接口但是是浅拷贝。实现了Seriable可以进行序列化。 ArrayList是一个基于数组实现的可变数组，数组长度取决于使用的构造函数和传的初始参数，在添加元素过程中可以动态以1.5倍扩容。数组中的元素是有序的，元素可以是null。因此随机访问元素的时间复杂度为O(1)，但是插入和删除元素的时间复杂度为O(n)刚好和LinkedList相反(用链表实现的)。 非线程安全，如果需要线程安全需要使用Vector、Collections.synchronizedList(new ArrayList())、CopyOnWriteArrayList 数组初始容量(DEFAULT_CAPACITY)是10 部分源码分析ArrayList(int initialCapacity)如果设置的初始容量为0，数组指向长度为0的数组。 12345678910public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125; ArrayList()如果没有指定数组长度，将默认指向另一个(区别于设置的初始长度为0)长度为0的数组。这里和上面形参为0指向的长度为0的数组不一样，目的是可以以此为标识，在首次添加元素时，执行不同的的扩容操作。无参构造函数在首次添加元素时，数组会扩容成10(0 -&gt; 10 -&gt; 20)，而形参为0的构造函数在首次添加元素时，只会在0的基础上1.5倍扩容（0 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 6）。至于这么做的原因，暂时没想到性能上会带来哪些提升，唯一能想到的就是为了统一？？为了区分不同的构造函数？？TODO。。。 下面是Java Doc： Shared empty array instance used for default sized empty instances. We distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when first element is added. 123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; ArrayList(Collection&lt;? extends E&gt; c)主要是第二个if，其他两个构造函数逻辑比较简单。 123456789101112131415/** * 将容器c中的元素构造成一个ArrayList，主要看第二个if * */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) // 防止继承ArrayList的子类重写toArray返回数组元素类型不是Object，比如是String,当add(1)时候就会抛StoreException异常。 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; add(E e)添加元素，主要涉及了一些扩容的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 添加元素：先判断数组容量，然后在添加 * */public boolean add(E e) &#123; // 先判断数组是否已满或者说判断数组是否还有空间 ensureCapacityInternal(size + 1); // Increments modCount!! // 添加元素 elementData[size++] = e; return true;&#125;/** * 确保数组容量够 * */private void ensureCapacityInternal(int minCapacity) &#123; // 先判断是否是初次添加元素 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 判断是否需要扩容 ensureExplicitCapacity(minCapacity);&#125;/** * 判断是否需要扩容 * */private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code // 如果需要的容量大于当前数组的容量 =&gt; 1.5倍扩容 if (minCapacity - elementData.length &gt; 0) // 扩容 grow(minCapacity);&#125;/** * 将elementData指向一个新的数组 * */private void grow(int minCapacity) &#123; // 获取旧数组长度 int oldCapacity = elementData.length; // 扩大1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果扩容以后还比需要的容量小，则将需要的容量赋值给新容量 /* 比如使用的是第三个构造函数，传入的c的size为1。 此时elementData.length = 1;如果调用add，此时传入的minCapacity = size + 1 = 2; 但是newCapacity = 1 + 1 /2 = 1 &lt; minCapacity，所以有的这个if 在或者 使用形参为0的构造函数 */ if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果扩容以后大于数组设置的最大容量，如果当前需要的容量小于数组最大容量，就扩展到数组的最大容量，否则就设置为Integer.MAX_VALUE // 设置 最大容量的一个目的是：有些虚拟机会在数组中保留一些头部信息，所以可能会造成内存溢出，所以不到万不得已，尽量不超过MAX_ARRAY_SIZE，下面是Java Doc // Some VMs reserve some header words in an array. Attempts to allocate larger arrays may result in OutOfMemoryError: Requested array size exceeds VM limit if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 重新拷贝数组 elementData = Arrays.copyOf(elementData, newCapacity);&#125;/** * 如果minCapacity小于MAX_ARRAY_SIZE就不需要扩容那么大，直接返回MAX_ARRAY_SIZE * */private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; add(int index, E element)在指定下标添加元素，主要是理解这个函数的使用System.arraycopy(elementData, index, elementData, index + 1, size - index)下同↓ 123456789101112public void add(int index, E element) &#123; // 检查下标 rangeCheckForAdd(index); // 判断数组容量是否可以在继续放元素，来决定是否进行扩容。 ensureCapacityInternal(size + 1); // Increments modCount!! // 从原数组index开始拷贝到从目的数组的index + 1开始的元素。 挨个往后拱 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 此时index下标的元素已经放到index + 1，将index元素重新赋值即可。 elementData[index] = element; // 增加数量 size++;&#125; remove(int index)删除指定位置元素 12345678910111213141516171819public E remove(int index) &#123; // 下标检查，防止越界 rangeCheck(index); // 修改次数 modCount++; // 获取当前下标对应元素 E oldValue = elementData(index); // 如果删除的是最后一个元素，直接删除，不用移动数组其它元素。 int numMoved = size - index - 1; // 如果删除的不是最后一个元素，需要进行移动。 if (numMoved &gt; 0) // 就是将原数组的index + 1 拷贝到原数组的index开始以后的元素。 参数特点是原数组和目的数组一样。 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 方便GC及时回收 elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; trimToSize()扩容的反义词：缩容。重新创建一个数组，长度为ArryList中的size。目的是为了防止进行多次remove操作以后，数组长度特别大，但是仅有几个元素导致空间浪费。可以调用此方法重新修剪数组长度。 12345678public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; boolean contains(Object o)是否包含指定元素o 123public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0;&#125; int indexOf(Object o)找到指定元素o第一次出现的下标 12345678910111213public int indexOf(Object o) &#123; // 从前遍历即可 if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; int lastIndexOf(Object o)找到指定元素o最后出现的下标 12345678910111213public int lastIndexOf(Object o) &#123; // 从后往前遍历即可 if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; LinkedList介绍 继承自AbstractSequentialList抽象类(只是非常简单地实现了List相关方法) 实现了List接口、Deque接口(继承自Queue接口，说明LinkedList间接实现了Queue接口)、有关于栈Stack的操作(push、pop)。可以当作一个双向链表、双端队列、FIFO队列、栈。并且可以添加null，这点区别于ArrayDeque。 非线程安全,如果需要线程安全需要用到List list = Collections.synchronizedList(new LinkedList(...)); 部分源码分析(翻译:))public LinkedList(Collection&lt;? extends E&gt; c)接收一个Collection类型的变量构造一个LinkedList 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; // 检查索引范围 checkPositionIndex(index); // 将参数c转化成数组 Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; // 定义两个指针变量 Node&lt;E&gt; pred, succ; // 链表还没有元素，此时index == 0 &amp;&amp; size == 0; if (index == size) &#123; succ = null; pred = last; // 链表已经有元素，在原有基础上又要添加元素 &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true;&#125; public void clear()清除链表中的元素，额外置空操作的意思是将节点之间的链接都断开，虽然不是必须的，但是有助于分代GC 12345678910111213141516public void clear() &#123; // Clearing all of the links between nodes is "unnecessary", but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++;&#125; 其它实现了队列(Queue)/双端队列(Deque)接口 队列接口主要方法 peek();element()获取队头元素，如果队列为空，则返回null/则抛异常 offer(E e)队尾入队列 双端队列接口主要方法 offerFirst(E e);offerLast(E e)从队头/对尾入队列 peekFirst();peekLast()获取队头/队尾元素 pollFirst();pollLast()获取并移除队头/队尾元素 包含了栈(Stack)操作 push(E e) 入栈 pop() 出栈 JavaDoc建议用ArrayQueue作为队列或者栈的接口实现,因为它有着比LinkedList更好的性能。 不再建议使用Stack stack = new Stack(); Resizable-array implementation of the Deque interface. Array deques have no capacity restrictions; they grow as necessary to support usage. They are not thread-safe; in the absence of external synchronization, they do not support concurrent access by multiple threads. Null elements are prohibited. This class is likely to be faster than Stack when used as a stack, and faster than LinkedList when used as a queue. 总结LinkedList适合用来做链表/双向链表、双端队列的实现。当用到FIFO队列或者栈时，建议使用ArrayDeque作为实现。比如：Deque&lt;Integer&gt; stack = new ArrayDeque&lt;Integer&gt;();Queue&lt;Integer&gt; queue = new ArrayDeque&lt;Integer&gt;(); Q&amp;AArrayList和LinkedList本质区别就是数组和链表的区别 ArrayList是如何扩容的？ 当添加元素之前需要判断当前数组的容量和需要的容量的差异，当需要的容量大于数组的当前容量，就会重新申请1.5倍旧数组大小的新数组，然后将旧数组元素拷贝到新数组。注意的是扩容过程中可能会由于需要的空间大小超出最大值(Integer.MAX_VALUE)而出现OOM。 ArrayList和LinkedList的区别？ ArrayList用数组实现，数组占据了一段连续的内存空间，支持通过首地址+偏移量进行时间复杂度为O(1)的随机访问。但是随机插入/删除元素的时间复杂度为O(n)。 LinkedList用链表实现，链表中的每个节点在物理内存中并不相邻，所以不支持随机访问。随机插入/删除元素的时间复杂度为O(1)。 这里要区分一下随机访问和顺序访问，维基百科定义： 随机访问/存取(Random access)In computer science, random access (more precisely and more generally called direct access) is the ability to access an arbitrary element of a sequence in equal time or any datum from a population of addressable elements roughly as easily and efficiently as any other, no matter how many elements may be in the set. 总结就是，访问任意一个元素所用的时间 time(注意是时间，不是时间复杂度)，都是一样的。 顺序访问(Sequential access)In computer science, sequential access means that a group of elements (such as data in a memory array or a disk file or on magnetic tape data storage) is accessed in a predetermined, ordered sequence. 总结就是，如果要访问一个元素，就需要从前向后依次访问过去，直到目标元素，明显，访问任意一个元素所用时间是不一样的。 fail-fast机制？当使用List的迭代器Iterator的进行操作时，如果List的结构被其它线程修改了(比如添加/删除了一个元素),当前线程在迭代过程中会抛出ConcurrentModificationException。 在生成迭代器的时候会拷贝一份modcount变量到expectedModCount(modcount变量用来记录List被修改的次数)，每次迭代时会判断expectedModCount是否等于modcount变量，如果不相等就说明其它线程对List做了修改,此时会抛出异常而不是继续冒险以一种不确定的行为执行下去。 if the list is structurally modified at any time after the iterator is created, in any way except through the iterator’s own remove or add methods, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, non-deterministic behavior at an undetermined time in the future. fail-fast机制是用来检测BUG的，不能依赖这个异常来保证程序的正确性。抛出这个异常说明代码写的有问题。 Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. Fail-fast iterators throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: the fail-fast behavior of iterators should be used only to detect bugs. 参考 Java集合框架源码解读(1)——ArrayList、LinkedList和Vector]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java容器框架源码阅读笔记（零）Collection、Map]]></title>
    <url>%2F2018%2F07%2F19%2FCollection%2F</url>
    <content type="text"><![CDATA[Java容器中共有两个接口，分别是Collection和Map。Collection用于存放多个 “单个对象” ，而Map用于存放多个 “两个对象(键值对)” 。 Collectionjava.uti.Collection框架： 介绍Collection是存放单个对象的容器。 Collection里只能存放对象，不能存放基本类型。对于基本类型(boolean, int, long, float, double)，需要将其包装成对象类型后(Boolean, Integer, Long, Float, Double)才能放到容器里，不过编译器已经帮我们完成了打包和解包的操作。所以可以直接写list.add(1)，而不用list.add(Integer.valueOf(1)) List ArrayList: 基于数组实现的可变数组，非线程安全。 Vector: 和ArrayList类似，区别是通过synchronized实现了线程安全，但效率较低。 LinkedList: 双向链表 Queue LinkedList： 实现了双端队列Deque、FIFO队列Queue。 ArrayDeque： 基于循环数组实现了双端队列Deque、FIFO队列Queue。官方建议使用该类作为Queue和Stack的默认实现。 Set HashSet: 基于HashMap实现的集合。元素的遍历顺序和插入顺序不一致。 LinkedHashSet: 基于LinkedHashMap实现的集合。元素的遍历顺序和插入顺序一致。 TreeSet： 基于TreeMap实现的集合。元素有序的，顺序是按照key的自然顺序或者是定义的Comparator。 Mapjava.uti.Map框架： 介绍Map是存放键值对的容器。 HashMap：基于数组、链表、红黑树实现的键值对类型的数据结构，非线程安全。元素的遍历顺序和插入顺序不一致。 HashTable：和HashMap类似，但是线程安全，不过效率较低，不建议使用。建议用ConcurrentHashMap、Collections.synchronizedMap(new HashMap())代替。 LinkedHashMap：基于HashMap和LinkedList实现的Map。可以实现元素遍历顺序和插入顺序一致。也可以实现元素的遍历顺序和访问顺序一致。 TreeMap：基于红黑树实现的Map，元素有序的，顺序是按照key的自然顺序或者是定义的Comparator。 WeakHashMap：WeakHashMap也是一种Map，其中的Entry可以JVM自动清除释放。其余的操作和HashMap相同，不过没有用到红黑树。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synchronized底层实现]]></title>
    <url>%2F2018%2F07%2F10%2Fsynchronized%2F</url>
    <content type="text"><![CDATA[预备知识 Java对象（非数组）：用来存储锁，由对象头、实例数据、对齐填充数据组成。 对象头：由MarkWord、类型指针组成。32位JVM下的Markword占32位，存储的数据取决于锁的状态。 初始是无锁状态。 在运行期间MarkWord里存储的数据会随着锁状态的变化而变化 Monitor类型对象：重量级锁状态下，MarkWord里的指针指向的对象，ObjectMonitor(C++写的)对Monitor做的实现。 ObjectMonitor对象主要属性： _count用来记录当前线程获取的锁计数 _WaitSet存放处于wait状态的线程 _EntryList存放处于等待获取锁，处于block状态的线程队列。 _owner指向持有ObjectMonitor对象的线程 synchronized介绍 用来修饰方法（静态方法、实例方法）、代码块 常说的通过synchronized加锁就是指竞争获取对象头MarkWord重量级锁状态下指向的Monitor类型对象(ObjectMonitor)，但是JDK1.6之后有了优化。 可以保持原子性(加锁)、保持变量可见性(释放锁会将缓存刷新到主存)、不防止指令重排序（比如单例模式DoubleCheck还是会用到volatile防止指令重排序）、 原理 JDK1.6之前，在进入synchronized修饰的方法或代码块之前要先获取重量锁（指的是获取对象头指针指向的Monitor类型的对象） 当修饰的是静态方法获取的是类的Class对象对应的Monitor对象 当修饰的是实例方法获取的是该类的实例对象对应的Monitor对象 当修饰的是代码块需要自己指定 用synchronized修饰的代码块，编译阶段会在方法执行前后生成monitorenter、monitorexit指令。 JVM规范对于monitorenter指令描述： Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows: If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor. If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count. If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership. 每一个对象都有一个Monitor对象，线程通过执行monitorenter指令尝试获取Monitor对象的拥有权 如果拥有当前Monitor对象的线程数为0，则将_count++,当前线程称为Monitor对象的拥有者。 如果当前线程已经拥有了此Monitor对象，则将_count++即可。 如果其他线程已经拥有了此Monitor对象，则当前线程阻塞直到Monitor的计数_count==0,然后重新竞争获取锁。 JVM规范对于monitorexit指令描述： The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so. 执行monitorexit指令的线程必须是此Monitor对象的拥有者(否则会抛java.lang.IllegalMonitorStateException异常)，线程减少Monitor对象的锁计数，如果锁计数为0了，则线程不再是Monitor对象的拥有者，其他被这个Monitor对象阻塞的线程可以尝试获取Monitor（之前因没竞争到锁而阻塞的线程需要被执行monitorexit指令的线程唤醒才能重新竞争锁）。 获取重量锁过程 当线程执行到monitorenter指令，会进入ObjectMonitor对象的_EntryList队列，通过CAS会将_owner指针指向当前线程，同时_count++， 当前线程执行monitorexit指令，会释放持有的Monitor对象，并将_owner置为null同时_count– 如果调用wait()，同上，但是会进入_WaitSet队列,等待被唤醒。(wait状态的线程在唤醒之后，需要进入_EntryList重新获取锁④，然后执行完毕，退出释放锁) 锁优化 原因：因为获取重量级锁过程中，比如将_owner指向当前线程调用的函数涉及到了特权指令Mutex Lock导致用户态和内核态的切换，影响效率(因为线程在用户态和内核态都有各自的堆栈、PC、寄存器。当从用户态切换到内核态时需要保存用户态对应的堆栈信息、寄存器、程序计数器的值到内核态的堆栈中，还要通过CPU中的eax ebx ecx等寄存器传递参数到内核态，内核态还要对用户态传入的参数做安全性检查，切换回用户态后还需要恢复用户态现场所以效率会比较低) JDK1.6做了优化，执行monitorenter指令时不会直接获取重量锁，而是先尝试获取偏向锁，=&gt; 轻量锁 =&gt; 重量级锁。 偏向锁相对于轻量级锁减少了CAS操作的次数，轻量级锁相对于重量级锁减少了系统调用。 获取偏向锁过程 原因:大部分情况下不会存在线程竞争，而且只会有同一个线程进入临界区，为了减少同一线程获取锁带来的消耗，所以当进入临界区前不会先去获取重量锁，而是先获取偏向锁。 膨胀成轻量级锁：偏向锁主要是为了解决同一个线程进入临界区，当有超过一个线程竞争偏向锁，就会膨胀为轻量级锁。 获取偏向锁过程： 先判断是否能开启偏向锁，如果可以 =&gt; 将偏向锁偏向线程ID用CAS(相对于轻量级锁获取和释放都需要CAS操作费时，偏向锁只有这一次)修改为当前线程ID。 获取轻量锁过程 原因:在多个线程都会尝试进入临界区的情况下，多个线程只会交替进入临界区，不会存在锁竞争，为了减少重量级锁系统调用造成的消耗。 膨胀成重量级锁：当多个线程同一时间都尝试获取锁，则会膨胀为重量级锁。 获取轻量级锁获取过程： 如果当前无锁并且不可偏向，会尝试获取轻量级锁，将MarkWord拷贝到当前线程的栈帧中的LockRecord，然后通过CAS更新MarkWord内容为指向当前线程LockRecord的指针， 和偏向锁的区别：偏向锁是同一个线程多次获取锁，轻量级锁是多个线程交替获取锁。相同点是假定都不存在锁竞争。 自旋锁 原因：咳咳,还是大部分情况下，线程持有锁的时间很短，当一个线程获取锁了以后，其他线程尝试获取锁就会进入阻塞状态，挂起-&gt;恢复都需要在用户态和内核态之间进行切换。此时如果让后来的线程进行自旋一段时间(for循环)，在获取锁，可能就会获取，也就避免了转入内核态。 JDK1.6引入了自适应的自旋锁，即根据具体情况结合前面旋转的次数决定此次需要旋转的次数。 优点：如果线程占用锁的时间比较短则自旋操作很有效，避免进入内核态 缺点:如果线程占用锁的时间比较长则自旋操作白白耗费CPU资源，倒不如挂起。 其他 当修饰方法会在常量池生成ACC_SYNCHRONIZED，当执行某个方法时会如果遇到此指令会同上… 123456public class Test &#123; synchronized void test() &#123; synchronized (this.getClass()) &#123;&#125; &#125;&#125; 参考 https://www.cnblogs.com/kundeg/p/8422557.html#_label2 http://www.infoq.com/cn/articles/java-se-16-synchronized http://bigdatadecode.club/JavaSynchronizedTheory.html http://www.cnblogs.com/paddix/p/5405678.html https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.monitorenter]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
        <tag>JMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal应用及原理]]></title>
    <url>%2F2018%2F07%2F05%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal是一个用于创建线程局部变量的类。当前线程通过ThreadLocal的set()方法设置的变量只对当前线程可见，通过get()获取设置的变量。 使用 支持泛型 1ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); 当前线程通过ThreadLocal对象的set(value)/get()设置变量和获取设置的变量 12threadLocal.set("jinshuai");threadLocal.get(); 原理 每个线程Thread维护一个ThreadLocalMap&lt;key,value&gt; key是ThreadLocal对象，value是通过set(value)设置的值 当前线程调用threadLocal.set(“jinshuai”); 首先获取当前线程所维护的ThreadLocalMap 然后判断当前线程是否已经创建过这个ThreadLocalMap 如果已经创建，会将ThreadLocal对象当作key，和当前线程要设置的值当作value放到ThreadLocalMap。 如果没有创建，会创建并初始化一个ThreadLocalMap（类似HashMap 初始化数组长度为2的幂，设置扩充阈值…）然后同上↑ 1234567891011121314public void set(T value) &#123; // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取线程的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;// 获取ThreadLocalMapThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 当前线程调用threadLocal.get(); 首先获取当前线程所维护的ThereadLocalMap 然后将ThreadLocal对象作为key获取对应的Entry 如果Entry不为空获取Entry的value 如果Entry为空直接返回一个setInitvalue()值也就是null 123456789101112131415161718public T get() &#123; // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取当前线程对应的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) &#123; // 将ThreadLocal(this)作为key获取entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") // 获取entry的value T result = (T)e.value; return result; &#125; &#125; // 如果entry为空 return setInitialValue();&#125; 应用场景 如果一个对象非线程安全，但又不想通过加锁的方式实现线程安全，可以通过ThreadLocal.set()对象的值,比如SimpleDataFormat不是线程安全的，此时可以每个线程设置一个SimpleDataFormat对象 123456789private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = new ThreadLocal&lt;&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat("yyyyMMdd HHmm"); &#125;&#125;;public String formatIt(Date date) &#123; return formatter.get().format(date);&#125; 当某一个变量比如User对象在多个方法中传递时，会变得比较乱此时可以通过ThreadLocal设置变量 比如在Servlet中： 123456doGet(HttpServletRequest req, HttpServletResponse resp) &#123; User user = getLoggedInUser(req); doSomething(user) doSomethingElse(user) renderResponse(resp,user)&#125; 每个方法都需要一个user，不够优雅(咳咳…)，此时可以通过设置一个ThreadLocal单例，然后set(user)： 123456789101112131415161718doGet(HttpServletRequest req, HttpServletResponse resp) &#123; User user = getLoggedInUser(req); ThreadLocalSingleInstace.getThreadLocal().set(user) try &#123; doSomething() doSomethingElse() renderResponse(resp) &#125; finally &#123; ThreadLocalSingleInstace.getThreadLocal().remove() &#125;&#125;// 获取ThreadLocal单例class ThreadLocalSingleInstace &#123; static private ThreadLocal threadLocal = new ThreadLocal&lt;User&gt;(); static ThreadLocal&lt;User&gt; getThreadLocal() &#123; return threadLocal; &#125;&#125; 注意 用完以后应该调用remove()移除设定的值，防止内存泄漏 12// 会移除这个EntrythreadLocal.remove(); 在线程池中由于线程会被复用，所以不会停止，导致每个线程中ThreadLocalMap里的key和虚引用Entry关联(Entry继承了虚引用)，GC时会将key引用的对象回收，但是Entry中的value对象一直有一个强引用value不会被回收造成内存泄漏。 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 参考 https://droidyue.com/blog/2016/03/13/learning-threadlocal-in-java/ http://blog.xiaohansong.com/2016/08/06/ThreadLocal-memory-leak/# https://stackoverflow.com/questions/817856/when-and-how-should-i-use-a-threadlocal-variable https://stackoverflow.com/questions/1490919/purpose-of-threadlocal]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代理]]></title>
    <url>%2F2018%2F06%2F26%2Fproxy%2F</url>
    <content type="text"><![CDATA[预备知识 反射：可以在运行期间分析某个类，每个类在JVM方法区都有一个Class对象，用来描述这个类的信息，比如这个类有什么属性，什么方法，修饰符等，通过Class对象可以创建对应类的实例,比如通过newInstance(); 代理 为某个对象提供一个代理，以控制对这个对象的访问，好比明星的经纪人是明星的代理，和明星商量事之前可能需要经过他的经纪人。 代理可以将一些非业务逻辑代码交由代理对象进行处理，比如记录日志、记录某个操作耗时。 静态代理 通过事先写好的代理类的源代码，在编译阶段生成相应的字节码文件，即在程序运行之前就确定了代理类。 创建一个类的代理对象可以通过创建该类的子类，然后重写要代理的方法。 12345678910111213141516171819202122232425// 客户端public class Client() &#123; // 被代理类 static class LoginService &#123; public void login()&#123; do(); &#125; &#125; // 代理类 static class LoginServiceProxy extends LoginService &#123; @Override public void login() &#123; log.info("开始登录"); super.login(); log.info("登录结束"); &#125; &#125; // 测试 public static void main(String[] args) &#123; LoginService loginService = new LoginServiceProxy(); // 实现上调用的是代理对象的login(); loginService.login(); &#125;&#125; 如果被代理类实现了接口，还可以通过创建一个实现了被代理类实现的接口的代理类对象。 1234567891011121314151617181920212223242526272829303132333435363738// 客户端public class Client() &#123; interface ILoginService &#123; void login(); &#125; // 被代理对象 static class LoginService implements ILoginService &#123; @Override public void login() &#123; do(); &#125; &#125; // 代理对象类，提前写好 static class LoginServiceProxy implements ILoginService &#123; // 需要有被代理对象的引用 LoginService loginService; Proxy(LoginService loginService) &#123; this.loginService = loginService; &#125; @Override public void login() &#123; log.info("开始登录"); loginService.do(); log.info("登录结束"); &#125; &#125; public static void main(String[] args) &#123; ILoginService loginService = new LoginServiceProxy(); // 实现上调用的是代理对象的login(); loginService.login(); &#125;&#125; 优点：将非业务代码抽取出来，减少耦合性。 缺点：如果被代理的方法数量较多的话，工作量会较大。 动态代理 在编译阶段不会生成字节码文件，在运行期间通过反射创建代理对象。 在Java里有JDK动态代理或者CGLIB动态代理两种实现。 JDK动态代理 在运行期间，Proxy会生成目标类的代理类的字节码，通过类加载器加载进虚拟机，最终通过反射来创建代理类的实例。代理类默认继承了Proxy，并且实现了目标类实现的接口。 要求 被代理对象所属的类需要实现接口 创建一个处理器InvocationHandler用于集中处理方法调用 被代理对象和代理对象是兄弟关系 12345678910111213141516171819202122232425262728293031323334353637383940414243public interface ITarget &#123; void sayHello();&#125;// 被代理对象，需要实现接口public class Target implements ITarget &#123; @Override public void sayHello() &#123; System.out.println("hello world"); &#125;&#125;// 处理器public class Handler implements InvocationHandler &#123; // 被代理对象 Object target; Handler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object Proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("before"); Object result = method.invoke(target,args); System.out.println("end"); return result; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; // 创建处理器，并传入被代理对象 Handler handler = new Handler(new Target()); // Proxy通过反射创建代理对象 // 代理对象是实现了目标对象的接口的一个对象，所以强制转换成目标对象（Target），就会报错，应该转换成它们共同的接口(ITarget) ITarget proxyInstance = (ITarget) Proxy.newProxyInstance(Target.class.getClassLoader(), Target.class.getInterfaces(),handler); // 实际调用的代理对象的sayHello(); proxyInstance.sayHello(); &#125;&#125; CLGLIB动态代理 在运行期间通过ASM解析目标类的字节码，进行修改（为了生成被代理对象的子对象），形成新的字节数组，重新通过类加载器ClassLoader加载到虚拟机中，通过反射创建代理对象，此代理对象是被代理对象的子对象。 要求 被代理对象不能用final修饰，因为需要创建被代理对象的子对象作为代理对象 被代理对象和代理对象之间是父子关系 12345678910// 创建一个增强器，用来在运行时生成类Enhancer ch = new Enhancer();// 设置要继承的目标类eh.setSuperclass(Target.class);// 设置拦截器，通过回调实现，类似JDK动态代理里的InvocationHandler处理器eh.setCallback(new XXXInterceptor());// 生成新的代理类Target target = (Target)eh.create();// 调用代理类的方法target.function(); 参考 https://mp.weixin.qq.com/s/cTJ_IankiFOdwZZLq3mHQA https://mp.weixin.qq.com/s/D_W8zTz38dKQBq3Tzm42Xg https://mp.weixin.qq.com/s/ax288tkY1YIClmEl5Dg1Hg http://layznet.iteye.com/blog/1182924 https://www.jianshu.com/p/23d3f1a2b3c7]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile底层实现]]></title>
    <url>%2F2018%2F06%2F25%2Fvolatile%2F</url>
    <content type="text"><![CDATA[预备知识 可见性：当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。 重排序：如果在单线程下对于指令的重排不会影响逻辑，那么在可以提高运行效率的前提下会进行适当的指令重排。 缓存行：CPU中的缓存是分段的，一段对应一个存储空间，称为缓存行，缓存行是CPU缓存中可分配的最小存储单元。 CPU缓存：为了解决CPU运算速度和内存读取速度不一致问题，CPU加入了缓存机制（L1、L2、L3），CPU通过系统总线、IO桥、内存总线从主内存中读取数据到CPU缓存中，此后将会从缓存中读取数据，进行运算然后刷新缓存。如果是单核CPU没什么问题，但在多核CPU下，各个核对自己缓存中的数据进行修改，但其它核并不知道，会造成各个核中的缓存不一致。 嗅探技术：每个核都可以”嗅探”到其它核缓存中共享变量的状态(MESI)、以及对缓存和主存的读写操作。 缓存一致性协议 实现一：BusLocking（总线锁）:通过对总线进行加锁。当一个核对其缓存中的变量进行操作时就会对总线发一个Lock#信号，其它核收到该信号（嗅探技术）就不会继续操作自己缓存中的该变量，当操作结束释放锁以后其它核就会重新从主内存中读取该变量到缓存中。 缺点：总线锁会降低性能。 实现二：MESI：通过在缓存行上设置状态标志位。在MESI协议中，每个核缓存对应的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它核对其缓存的读写操作，并根据其操作修改自己缓存标志位。 当前状态 说明 M 当前核缓存的变量与主内存不一致 E 缓存的变量只存在当前核 S 各个核中缓存的变量处于一致状态 I 当前核中缓存的变量无效 举个例子：当核1中缓存的变量状态从S变为M，同时核2通过嗅探技术，嗅探到此操作，然后会使其缓存行标志位变为I，当核2再读取对应数据时，会判断其它核中缓存的此数据的标志位，发现核1的缓存行标志位是M，则会触发将核1中的缓存行刷新到主内存中，然后核2从主内存中读取到缓存中。 Lock汇编指令： 将当前核中的对缓存的修改刷新到主内存中 会锁定当前缓存，将当前缓存中的数据回写到主存中。并通过缓存一致性协议保证操作是原子操作。 使其它核中的缓存无效 回写到主存中的操作会导致其它核中缓存的失效 此指令相当于一个内存屏障，保证不会将此指令之前的操作和此指令之后的操作和此指令进行重新排序。 volatile概述 volatile用来修饰变量，使得变量具有可见性。同时保证对此变量的操作指令不会发生重排序 对于volatile变量的操作没有相关的加锁操作，性能会比synchronized要高。 不保证原子性 原理 可见性 对于volatile变量的写操作会生成lock汇编指令，导致将缓存回写到主存中，并且使其它线程的工作内存(对应到CPU核的缓存)的此变量失效(就是MESI协议里的Invalid状态) 比如在线程A，线程B工作内存中缓存着主内存中的变量a（对应底层的cpu核缓存的状态就是a的状态为S)当线程A将工作内存中a = 1，此时线程B中的a失效，当线程B再次读取a的时候需要从主内存中重新读取。 有序性 执行lock汇编指令时会保证它之前的操作已经执行完毕，并且对其后的操作可见，即只有执行完了lock指令才会执行后续的操作。 不保证原子性 反证：假如核1，核2都将共享变量a（初始为0）读到缓存进行修改，核1将a++，核2将a += 3，此时核1将缓存中的a修改为1，导致核2缓存里的a变为Invalid。当核2回写缓存a = 3的时候，发现a所在缓存行状态是Invalid，导致核2需要从主存中读 a = 1，此时会触发核1的缓存中的a = 1刷新到主存中，然后核2从内存中读取a = 1并修改自己的缓存中的a = 1，并没有和预期的a最终变为4相符，即不保证原子性。 后续就是核1的对a的缓存状态变为I，核2变为M 应用场景 不与其它状态变量共同参与不变约束(比如volatile int a;while(a &gt; b) 而b就是其它状态变量) 对此变量的写操作不依赖与当前值(比如a = 1就是不依赖当前值，a = a + 1就依赖了当前值) 应用例子 作为状态变量,因为它的可见性保证当它修改以后 其他线程可以及时看到。 123456789101112131415public class Main &#123; private volatile boolean shutdown = false; public void do() &#123; while (!shutdown) &#123; // doSomething(); &#125; &#125; public void shutdown() &#123; shutdown = true; &#125;&#125; 懒汉式单例模式双重检测（Double Check） 1234567891011121314151617181920212223public class Main &#123; private static volatile Main obj; public static Main getInstance() &#123; if (obj == null) &#123; synchronized(this.getClass()) &#123; if (obj == null) &#123; /* new 操作会执行三个操作 1. 分配内存 2. 初始化内存 3. 将引用执行内存，返回引用 但2. 3. 可能重排序，导致没有初始化内存就将引用变量obj返回，此时并不是预期的Main对象。 */ obj = new Main(); &#125; &#125; &#125; return obj; &#125;&#125; 不严格的读写锁策略 读的时候并没有排斥写，适用更新不频繁的情况。 123456789101112131415public class Main &#123; private static volatile int i; // 可见性保证最新的 public int read() &#123; return i; &#125; // 直接加锁保证对依赖当前值的操作具有原子性 public synchronized void increase() &#123; i++; &#125; &#125; 参考 http://www.infoq.com/cn/articles/ftf-java-volatile#anch134390 https://en.wikipedia.org/wiki/MESI_protocol https://www.ibm.com/developerworks/cn/java/j-jtp06197.html https://crowhawk.github.io/2018/02/10/volatile/ https://www.cnblogs.com/xrq730/p/7048693.html https://read.douban.com/ebook/15233695/ http://www.ixirong.com/2015/08/22/java-volatile/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
        <tag>JMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[停止一个线程]]></title>
    <url>%2F2018%2F06%2F22%2FStopThread%2F</url>
    <content type="text"><![CDATA[预备知识 interrupt() Thread的非静态方法，标记当前线程的中断状态为true; isInterrupted() Thread的非静态方法，查看当前线程的中断状态; interrupted() Thread的静态方法，查看当前线程的中断状态，并清除(将状态改为false)； 如果当前线程设置了中断，然后调用sleep()/wait()/join()或者当前线程处于sleep()/wait()/join()然后中断该线程会抛出InterruptException，并且会清除中断状态。 volatile 修饰变量，使得被修饰的变量修改以后引起其他线程工作内存中对此变量的缓存无效，进而保持可见性。 停止线程通过轮询线程的中断状态 通过设置中断状态，进而通过轮询中断状态决定是否停止。 1234567891011public class ThreadDemo implements Runnable &#123; @Override public void run() &#123; // 轮询中断状态 while (Thread.currentThread().isInterrupted()) &#123; doSomething(); &#125; &#125;&#125; 如果在while里面使用了sleep()/wait()/join(),此时如果通过设置线程中断状态停止线程，会抛出InterruptException，会清除中断状态，导致不会正常停止，所以需要重新设置线程中断状态。 12345678910111213141516public class ThreadDemo implements Runnable &#123; @Override public void run() &#123; while (!Thread.currentThread().isInterrupted()) &#123; doFirstPartOfIncrement(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; // 抛出了InterruptException，此时会清除当前线程的中断状态，需要重新设置中断状态，保证线程正常终止 Thread.currentThread().interrupt(); &#125; &#125; &#125;&#125; 通过轮询共享变量 通过设置共享变量，进而通过轮询共享变量决定是否停止。 1234567891011121314151617public class ThreadDemo implements Runnable &#123; // 状态变量 private volatile boolean stop = false; public void stop() &#123; stop = true; &#125; @Override public void run() &#123; // 轮询状态变量 while (!stop) &#123; doSomething(); &#125; &#125;&#125; 通过Thread.stop() JDK已经标记为@Deprecated This method is inherently unsafe. Stopping a thread with Thread.stop causes it to unlock all of the monitors that it has locked (as a natural consequence of the unchecked ThreadDeath exception propagating up the stack). If any of the objects previously protected by these monitors were in an inconsistent state, the damaged objects become visible to other threads, potentially resulting in arbitrary behavior. 会将此线程获取的Monitor对象（也就是常说的通过synchronized获取的锁）释放。比如一个线程负责维护一个对象Product中的两个变量saleCount和StockCount处于saleCount &lt;= stockCount状态，当某个时刻saleCount &gt; stockCount,同时此线程被stop()强制停止，会导致逻辑错误。 参考 http://ibruce.info/2013/12/19/how-to-stop-a-java-thread/ https://stackoverflow.com/questions/3194545/how-to-stop-a-java-thread-gracefully https://stackoverflow.com/questions/10630737/how-to-stop-a-thread-created-by-implementing-runnable-interface]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
